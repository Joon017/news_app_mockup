from flask import Flask, jsonify, request
from flask_cors import CORS
from os import environ
import json
import pymongo
from bson import ObjectId
from openai import OpenAI
# from openai import AzureOpenAI
from sentence_transformers import SentenceTransformer
import time
from datetime import date 

embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')

# IMPORT CHROMADB
import chromadb
chroma_client = chromadb.Client()
from chromadb.utils import embedding_functions
sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-mpnet-base-v2")

# FLASK APP
app = Flask(__name__)

# CROSS ORIGIN RESOURCE SHARING
CORS(app)

# OPENAI
# openai_client = OpenAI(api_key = "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")
openai_client = OpenAI(api_key = "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")

# AZURE OPENAI
# openai_client = AzureOpenAI(api_key="cfd349e9242e4495bad6aa347a16b0c9",azure_endpoint="https://chatbotapi1.openai.azure.com",api_version='2023-05-15')


# CONNECT TO MONGO
mongo_client = pymongo.MongoClient("mongodb+srv://ckoh2021:MGk9TVzCl4RgRYHN@cluster0.euvgj72.mongodb.net/")

# CONNECT TO NEWSSCRAPER DB
news_scraper_db = mongo_client.get_database('NewsScraper')

# COLLECTIONS IN DB
articles_collection = news_scraper_db.get_collection('Articles')

# UPLOAD ARTICLES TO DB - MONGO (AS SUMMARISED ARTICLES) + CHROMADB (AS ORIGINAL ARTICLES)
# UPLOAD'S RECEIVED ARTICLES FROM SCRAPER TO THE DB
# FOR FUTURE USE - TO DELETE ARTICLES WHICH ARE OUTDATED IN THE DB 

@app.route("/upload", methods=['GET', 'POST'])
def upload_articles():

  # FOF EVENTUAL IMPLEMENTATION 
  input_data = request.get_json() 
  all_articles = input_data["scraped_articles"]
  print(all_articles)

  # CREATE A 2D ARRAY TO STORE ARTICLES_1, ARTICLES_2, ARTICLES_3
  #   all_articles = [
  #   {
  #   "title": "Changing face of invention in the age of AI",
  #   "topic": "Generative AI",
  #   "source": "Techxplore",
  #   "source_url": "Techxplore.com",
  #   "article_url": "https://techxplore.com/news/2023-12-age-ai.html",
  #   "publish_date": "20-12-2023",
  #   "content": "Credit: Pixabay/CC0 Public Domain With the widespread adoption of generative AI tools like ChatGPT, we can no longer assume that new ideas and inventions are solely the result of human effort. As an organization driven by innovation and invention, Intellectual Property (IP) is CSIRO's primary output. So, what does this mean for inventors and the IP they create? We've heard many perspectives recently on the effect generative AI will have on all facets of how we work, conduct business, and ultimately live our lives. When game-changing technologies emerge, there's a tendency for people to polarize in opinion, either vastly underestimating or vastly overestimating the benefits and problems associated with using them. For example, we've heard how AI could never produce art or how it will solve all our collective problems. But no matter what our opinions are on the dangers and benefits of AI, these tools don't exist in isolation. People using and creating generative AI tools and the tools themselves are subject to IP laws. Being aware of these laws can help protect us from their impact. When the tools we create become the creators From the perspective of an artist, creator or author, there's a strong argument they should have a right to control how their work is used or exploited. Copyright laws generally achieve this goal. Typically, these laws rely on the legal concept of \"individual intellectual effort\" to determine who the author of a work is. That is, the person creating the work needs to have added enough of their own ingenuity and creativity to distinguish their creation from other existing works. But how does a human achieve this? Some argue that unlike AI, there's something special about humans that allows us to achieve the creation of a \"new\" work. I propose a different argument. The work a human creates is simply the sum total of all the things that human has sensed and experienced throughout their lifetime. Similarly, an AI tool creates an output based on the sum total of all the data it has consumed throughout its training. With time, the data that an AI consumes will grow as its sensor inputs and ability to experience become more sophisticated. There's a critical point where AI tools will exceed humans in their ability to sense and experience, and consequently exceed humans in their capability to create, author or invent. At the very least, this will happen in specific domains. For example, AI's in the specific domain of chess exceeded human capability years ago, and we're witnessing it again now in the visual arts thanks to tools like Dall-E and Midjourney. Humans vs. AI in Intellectual Property law Many jurisdictions have decided only \"real humans\" can be considered the author, creator, or inventor for the purposes of IP law. But often it's unclear who is considered the creator of a work when an AI tool is used. In the current generation of high-profile generative AI tools, text prompts are used as the input mechanism to produce a desired output. The question is, by entering a specific set of prompts into an AI tool, did a human apply sufficient effort to be considered the author, inventor or creator of the output work? If not, and the work is not considered a copy of any other work, then from where did the ingenuity or inventive effort come? This line of thinking leads to several problems for people using and creating these tools, especially when it comes to proving they are the creator. More broadly, it poses problems for the entire IP system. Let's hone in on the patent system as an example. One requirement for patenting is that a new invention must be \"inventive,\" \"not-obvious,\" contain an \"inventive step,\" or other similar requirements across jurisdictions. The test for meeting this threshold is often defined as whether a person skilled in an area of technology, with access to their normal working tools, would consider the invention \"routine,\" as \"a matter of course,\" or \"obvious.\" If generative AI is used as a matter of course in an area of technology, and can produce an acceptable description of an invention, then the bar for patenting is significantly raised. That is, once generative AI tools become common place (maybe they already are), we can expect a person skilled in a particular area of technology will use them to solve their problems. But what happens when an AI tool has become so proficient that it has collected every piece of data that a human could, and has awareness of every experience that a human could have? The AI would be able to conceive a solution to every problem that a human could, just as the chess computer knows every move a grandmaster may consider. The result is almost nothing is inventive anymore, unless the human inventor has new data they can input to which no other party (including the AI tool) has access. This scenario helps to illustrate the issues that IP law and individuals face. It is likely that over the coming years step changes in technology will be taken that lawmakers will need to respond to. But, we don't yet know how these problems will be resolved. Given that no significant legal changes have been made in the face of the current generation of AI, and the rate of change is likely to accelerate, inventors and innovators should attempt to stay ahead of any possible changes. Avoiding IP issues when using generative AI There are practical steps you can take right now to help ensure you're considered the creator, author, or inventor of something made with the assistance of generative AI. Most importantly, be careful to document how and when you interact with AI tools, and what data you use for to gain an output. For the current generation of AI tools, this means you should record the prompts you use, when they were made, and with what version of tool. This could be crucial evidence down the track to show sufficient 'intellectual effort' was used, proving you're the rightful author or inventor. If you're creating new AI tools, you should verify that you have sufficient rights in the datasets used to train the tools. This ensures the AI model that forms the basis of your tool can't inadvertently create a copy or a derivative work that would infringe on others' rights. It's likely more jurisdictions will require disclosure about training datasets as time goes on. And finally, when using an AI tool , it's important to remember that you're accepting a license. That license affects your rights in the works, ideas or data output by the AI. Always read the fine print. Despite the uncertainty and potential for massive changes, you can still get creating, inventing, and authoring\u2014but know how to protect yourself, and do it responsibly. Provided by CSIRO Citation : Changing face of invention in the age of AI (2023, December 20) retrieved 22 December 2023 from https://techxplore.com/news/2023-12-age-ai.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
  #   "scraped_date": "22-12-2023"
  # },
  #   {
  #     "title": "Study shows AI image-generators being trained on explicit photos of children",
  #     "topic": "Generative AI",
  #     "source": "Techxplore",
  #     "source_url": "Techxplore.com",
  #     "article_url": "https://techxplore.com/news/2023-12-ai-image-generators-explicit-photos-children.html",
  #     "publish_date": "20-12-2023",
  #     "content": "David Thiel, chief technologist at the Stanford Internet Observatory and author of its report that discovered images of child sexual abuse in the data used to train artificial intelligence image-generators, poses for a photo on Wednesday, Dec. 20, 2023 in Obidos, Portugal. Credit: Camilla Mendes dos Santos via AP Hidden inside the foundation of popular artificial intelligence image-generators are thousands of images of child sexual abuse, according to a new report that urges companies to take action to address a harmful flaw in the technology they built. Those same images have made it easier for AI systems to produce realistic and explicit imagery of fake children as well as transform social media photos of fully clothed real teens into nudes, much to the alarm of schools and law enforcement around the world. Until recently, anti-abuse researchers thought the only way that some unchecked AI tools produced abusive imagery of children was by essentially combining what they've learned from two separate buckets of online images\u2014adult pornography and benign photos of kids. But the Stanford Internet Observatory found more than 3,200 images of suspected child sexual abuse in the giant AI database LAION, an index of online images and captions that's been used to train leading AI image-makers such as Stable Diffusion. The watchdog group based at Stanford University worked with the Canadian Centre for Child Protection and other anti-abuse charities to identify the illegal material and report the original photo links to law enforcement. It said roughly 1,000 of the images it found were externally validated. The response was immediate. On the eve of the Wednesday release of the Stanford Internet Observatory's report, LAION told The Associated Press it was temporarily removing its datasets. LAION, which stands for the nonprofit Large-scale Artificial Intelligence Open Network, said in a statement that it \"has a zero tolerance policy for illegal content and in an abundance of caution, we have taken down the LAION datasets to ensure they are safe before republishing them.\" While the images account for just a fraction of LAION's index of some 5.8 billion images, the Stanford group says it is likely influencing the ability of AI tools to generate harmful outputs and reinforcing the prior abuse of real victims who appear multiple times. It's not an easy problem to fix, and traces back to many generative AI projects being \"effectively rushed to market\" and made widely accessible because the field is so competitive, said Stanford Internet Observatory's chief technologist David Thiel, who authored the report. \"Taking an entire internet-wide scrape and making that dataset to train models is something that should have been confined to a research operation, if anything, and is not something that should have been open-sourced without a lot more rigorous attention,\" Thiel said in an interview. Students walk on the Stanford University campus on March 14, 2019, in Stanford, Calif. Hidden inside the foundation of popular artificial intelligence image-generators are thousands of images of child sexual abuse, according to a new report from the Stanford Internet Observatory that urges technology companies to take action to address a harmful flaw in the technology they built. Credit: AP Photo/Ben Margot, File A prominent LAION user that helped shape the dataset's development is London-based startup Stability AI, maker of the Stable Diffusion text-to-image models. New versions of Stable Diffusion have made it much harder to create harmful content, but an older version introduced last year\u2014which Stability AI says it didn't release\u2014is still baked into other applications and tools and remains \"the most popular model for generating explicit imagery,\" according to the Stanford report. \"We can't take that back. That model is in the hands of many people on their local machines,\" said Lloyd Richardson, director of information technology at the Canadian Centre for Child Protection, which runs Canada's hotline for reporting online sexual exploitation. Stability AI on Wednesday said it only hosts filtered versions of Stable Diffusion and that \"since taking over the exclusive development of Stable Diffusion, Stability AI has taken proactive steps to mitigate the risk of misuse.\" \"Those filters remove unsafe content from reaching the models,\" the company said in a prepared statement. \"By removing that content before it ever reaches the model, we can help to prevent the model from generating unsafe content.\" LAION was the brainchild of a German researcher and teacher, Christoph Schuhmann, who told the AP earlier this year that part of the reason to make such a huge visual database publicly accessible was to ensure that the future of AI development isn't controlled by a handful of powerful companies. \"It will be much safer and much more fair if we can democratize it so that the whole research community and the whole general public can benefit from it,\" he said. Much of LAION's data comes from another source, Common Crawl, a repository of data constantly trawled from the open internet, but Common Crawl's executive director, Rich Skrenta, said it was \"incumbent on\" LAION to scan and filter what it took before making use of it. LAION said this week it developed \"rigorous filters\" to detect and remove illegal content before releasing its datasets and is still working to improve those filters. The Stanford report acknowledged LAION's developers made some attempts to filter out \"underage\" explicit content but might have done a better job had they consulted earlier with child safety experts. Many text-to-image generators are derived in some way from the LAION database, though it's not always clear which ones. OpenAI, maker of DALL-E and ChatGPT, said it doesn't use LAION and has fine-tuned its models to refuse requests for sexual content involving minors. David Thiel, chief technologist at the Stanford Internet Observatory and author of its report that discovered images of child sexual abuse in the data used to train artificial intelligence image-generators, poses for a photo on Wednesday, Dec. 20, 2023, in \u00d3bidos, Portugal. Credit: Camilla Mendes dos Santos via AP Google built its text-to-image Imagen model based on a LAION dataset but decided against making it public in 2022 after an audit of the database \"uncovered a wide range of inappropriate content including pornographic imagery, racist slurs, and harmful social stereotypes.\" Trying to clean up the data retroactively is difficult, so the Stanford Internet Observatory is calling for more drastic measures. One is for anyone who's built training sets off of LAION\u20105B\u2014named for the more than 5 billion image-text pairs it contains\u2014to \"delete them or work with intermediaries to clean the material.\" Another is to effectively make an older version of Stable Diffusion disappear from all but the darkest corners of the internet. \"Legitimate platforms can stop offering versions of it for download,\" particularly if they are frequently used to generate abusive images and have no safeguards to block them, Thiel said. As an example, Thiel called out CivitAI, a platform that's favored by people making AI-generated pornography but which he said lacks safety measures to weigh it against making images of children. The report also calls on AI company Hugging Face, which distributes the training data for models, to implement better methods to report and remove links to abusive material. Hugging Face said it is regularly working with regulators and child safety groups to identify and remove abusive material. Meanwhile, CivitAI said it has \"strict policies\" on the generation of images depicting children and has rolled out updates to provide more safeguards. The company also said it is working to ensure its policies are \"adapting and growing\" as the technology evolves. The Stanford report also questions whether any photos of children\u2014even the most benign\u2014should be fed into AI systems without their family's consent due to protections in the federal Children's Online Privacy Protection Act. Rebecca Portnoff, the director of data science at the anti-child sexual abuse organization Thorn, said her organization has conducted research that shows the prevalence of AI-generated images among abusers is small, but growing consistently. Developers can mitigate these harms by making sure the datasets they use to develop AI models are clean of abuse materials. Portnoff said there are also opportunities to mitigate harmful uses down the line after models are already in circulation. Tech companies and child safety groups currently assign videos and images a \"hash\"\u2014unique digital signatures\u2014to track and take down child abuse materials. According to Portnoff, the same concept can be applied to AI models that are being misused. \"It's not currently happening,\" she said. \"But it's something that in my opinion can and should be done.\" \u00a9 2023 The Associated Press. All rights reserved. This material may not be published, broadcast, rewritten or redistributed without permission. Citation : Study shows AI image-generators being trained on explicit photos of children (2023, December 20) retrieved 22 December 2023 from https://techxplore.com/news/2023-12-ai-image-generators-explicit-photos-children.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "An AI-driven influence operation is spreading pro-China propaganda across YouTube, investigation finds",
  #     "topic": "Generative AI",
  #     "source": "Techxplore",
  #     "source_url": "Techxplore.com",
  #     "article_url": "https://techxplore.com/news/2023-12-ai-driven-pro-china-propaganda-youtube.html",
  #     "publish_date": "19-12-2023",
  #     "content": "Credit: Pixabay/CC0 Public Domain A recent investigation from the Australian Strategic Policy Institute (ASPI) has revealed an extensive network of YouTube channels promoting pro-Chinese and anti-US public opinion in the English-speaking world. The operation is well-coordinated, using generative AI to rapidly produce and publish content, while deftly exploiting YouTube's algorithmic recommendation system. How big is the network? Operation \" Shadow Play \" involves a network of at least 30 YouTube channels with about 730,000 subscribers. At the time of writing this article the channels had some 4,500 videos between them, with about 120 million views. According to ASPI , the channels gained audiences by using AI algorithms to cross-promote each other's content, thereby boosting visibility. This is concerning as it allows state messaging to cross borders with plausible deniability . The network of videos also featured an AI avatar created by British artificial intelligence company Synthesia, according to the report , as well as other AI-generated entities and voiceovers. While it's not clear who is behind the operation, investigators say the controller is likely Mandarin-speaking. After profiling the behavior, they concluded it doesn't match that of any known state actor in the business of online influence operations. Instead, they suggest it might be a commercial entity operating under some degree of state direction. These findings double as the latest evidence that advanced influence operations are evolving faster than defensive measures. Influencer conflicts of interest One clear parallel between the Shadow Play operation and other influence campaigns is the use of coordinated networks of inauthentic social media accounts, and pages amplifying the messaging. For example, in 2020 Facebook took down a network of more than 300 Facebook accounts, pages and Instagram accounts that were being run from China and posting content about the US election and COVID pandemic. As was the case with Shadow Play, these assets worked together to spread content and make it appear more popular than it was. Is current legislation strong enough? The current disclosure requirements around sponsored content have some glaring gaps when it comes to addressing cross-border influence campaigns. Most Australian consumer protection and advertising regulation focuses on commercial sponsorships rather than geopolitical conflicts of interest. Platforms such as YouTube prohibit deceptive practices in their stated rules. However, identifying and enforcing violations is difficult with foreign state-affiliated accounts that conceal who is pulling their strings. Determining what is propaganda, as opposed to free speech, raises difficult ethical questions around censorship and political opinions. Ideally, transparency measures shouldn't unduly restrict protected speech. But viewers still deserve to understand an influencer's incentives and potential biases. Possible measures could include clear disclosures when content is affiliated directly or indirectly with a foreign government , as well as making affiliation and location data more visible on channels. How to spot deceptive content? As technologies become more sophisticated, it's becoming harder to discern what agenda or conflict of interest may be shaping the content of a video. Discerning viewers can gain some insight by looking into the creator(s) behind the content. Do they provide information on who they are, where they're based and their background? A lack of clarity may signal an attempt to obscure their identity. You can also assess the tone and goal of the content. Does it seem to be driven by a specific ideological argument? What is the poster's ultimate aim: are they just trying to get clicks, or are they persuading you into believing their viewpoint? Check for credibility signals, such as what other established sources say about this creator or their claims. When something seems dubious, rely on authoritative journalists and fact-checkers. And make sure not to consume too much content from any single creator. Get your information from reliable sources across the political spectrum so you can take an informed stance. The bigger picture The advancement of AI could exponentially amplify the reach and precision of coordinated influence operations if ethical safeguards aren't implemented. At its most extreme, the unrestricted spread of AI propaganda could undermine truth and manipulate real-world events. Propaganda campaigns may not stop at trying to shape narratives and opinions. They could also be used to generate hyper-realistic text, audio and image content aimed at radicalizing individuals. This could greatly destabilize our societies. We're already seeing the precursors of what could become AI psy-ops with the ability to spoof identities, surveil citizens en masse, and automate disinformation production. Without applying an ethics or oversight framework to content moderation and recommendation algorithms, social platforms could effectively act as misinformation mega-amplifiers optimized for watch-time, regardless of the consequences. Over time, this may erode social cohesion , upend elections, incite violence and even undermine our democratic institutions. And unless we move quickly, the pace of malicious innovation may outstrip any regulatory measures. It's more important than ever to establish external oversight to make sure social media platforms work for the greater good, and not just short-term profit. Provided by The Conversation This article is republished from The Conversation under a Creative Commons license. Read the original article . Citation : An AI-driven influence operation is spreading pro-China propaganda across YouTube, investigation finds (2023, December 19) retrieved 22 December 2023 from https://techxplore.com/news/2023-12-ai-driven-pro-china-propaganda-youtube.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "Research finds people struggle to identify AI from human art, but prefer human-made works",
  #     "topic": "Generative AI",
  #     "source": "Techxplore",
  #     "source_url": "Techxplore.com",
  #     "article_url": "https://techxplore.com/news/2023-12-people-struggle-ai-human-art.html",
  #     "publish_date": "18-12-2023",
  #     "content": "According to research completed by a BGSU doctoral candidate, humans can correctly identify human-made art about half the time, similar to the rate of a coin toss. Above, only one of the two post-impressionist paintings\u2014Paul Cezanne's Banks of the Seine at Medan\u2014is manmade. The Paris landscape was made by AI. Credit: Bowling Green State University New research from Bowling Green State University finds that generative artificial intelligence\u2014or AI\u2014can blur the lines when it comes to identifying the source of images, but discovered humans still maintain a subsurface preference for genuine human art. Andrew Samo, a doctoral candidate studying industrial and organizational psychology at BGSU, published research along with Distinguished Research Professor Dr. Scott Highhouse on AI versus human artwork in the journal Psychology of Aesthetics, Creativity, and the Arts , which found that people generally can't tell the difference between AI and human art, but they prefer the latter\u2014even if they can't explain why. \"Art was thought to be uniquely human because it gives off a feeling or communicates some idea about the human experience that machines don't have,\" Samo said. \"In some ways, it's to be expected people felt more strongly about human-made art. \"But at the same time, it was surprising: How can people feel so differently about one, but not be able to cognitively explain why?\" Building from the past Prior research had found that humans tend to show bias against AI artwork, but as new, generative AI models continued to improve, Samo and Highhouse wondered if people would be able to tell the difference between AI art and human art without prodding. To answer their question\u2014and eliminate bias\u2014participants were not told that some of the art they would view would be made by AI. Instead, they were only told they would be viewing a series of pictures and rating them on 30\u201350 aesthetic judgment factors, a reliable, psychometrics-rooted method of quantifying artistic emotions and experiences. \"Previous research demonstrated that people are biased against art if they know it was made by AI, and they'll say they don't like it as much,\" Samo said. \"But no one had really looked at this new AI art without any kind of deception. I thought, \"If we just show people these images, would they even know which is made by humans and which is made by AI? And if they do know which one is which, how do we know what features distinguish them?\" What they found showed the capability of generative AI: Participants correctly identified the source of the artwork only slightly more than half the time, and even so, were not confident that their guesses were correct. \"It's really a coin flip\u2014when you show them the pictures, there's about a 50%\u201360% chance they'll get it right,\" Samo said. \"Generally, people don't know which is which, and when we asked how confident they were, they were typically saying they were only 50% confident. An unexplainable feeling The struggle in differentiating between originators of artwork came with another interesting finding: People prefer human artwork, even if they aren't totally sure why. After reviewing data, Samo and Highhouse found there were clear differences in how people felt about human artwork versus AI artwork. Even though participants were not confident in their identification of the source, they consistently felt more positively about human-generated art. \"They typically didn't know the difference and admitted they couldn't tell the difference once you asked them, but the next layer of that is people reliably said they liked the human images more without even knowing whether it was AI or not,\" Samo said. \"We found people have more positive emotions when looking at the human paintings, which makes sense.\" Out of all the aesthetic judgment factors, four accounted for the majority of the variance. Human-made art scored higher in self-reflection , attraction, nostalgia and amusement, a sign that people felt more connected to human art. But when asked why participants felt that way, they couldn't explain it. One interpretation is that their snap judgments connected with human art, but their analytical processing couldn't quite articulate why they felt that way. A theory the researchers discuss in the paper is the possibility that the brain picks up on tiny differences in art created by AI. \"One possible explanation could be the uncanny valley effect\u2014something that is trying to look human\u2014but there are these micro-perceptions that are slightly off,\" Samo said. \"Everything looks good holistically, but there are these small details in the visuals or creative narratives that your subconscious is picking up on the rest of you isn't.\" The next wave While AI was once believed to be able to replicate only certain tasks like those on an assembly line , for instance, generative models have shown the capacity to do much, much more. Samo and Highhouse's research is a glimpse into the possibilities of generative AI. \"For the longest time, AI was thought to be able to automate line work, data management, or anything else that's very repetitive, routine, or non-original,\" Samo said. \"But with generative AI models, they're able to not only do those repetitive tasks but come up with art, music, poetry, prose, text that is almost indistinguishable from humans. And this raises exciting possibilities for applications of generative AI.\" In the short time since Samo and Highhouse collected data, generative AI models have continued to improve and become more widely available. As AI evolves, Samo said it's important to continue to understand the psychological effects and human impacts of AI as models become more powerful and used in everyday life. \"Some of these new models can generate images that are really high quality and high fidelity toward the actual world, so it'd be interesting to run this study again,\" Samo said. \"If you redid this, I'm not sure if people would be able to tell the differences at all.\" More information: Andrew Samo et al, Artificial intelligence and art: Identifying the aesthetic judgment factors that distinguish human- and machine-generated artwork, Psychology of Aesthetics, Creativity, and the Arts (2023). DOI: 10.1037/aca0000570 Provided by Bowling Green State University Citation : Research finds people struggle to identify AI from human art, but prefer human-made works (2023, December 18) retrieved 22 December 2023 from https://techxplore.com/news/2023-12-people-struggle-ai-human-art.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "Open-source training framework increases the speed of large language model pre-training when failures arise",
  #     "topic": "Generative AI",
  #     "source": "Techxplore",
  #     "source_url": "Techxplore.com",
  #     "article_url": "https://techxplore.com/news/2023-12-open-source-framework-large-language-pre-training.html",
  #     "publish_date": "18-12-2023",
  #     "content": "Oobleck's planning algorithm overview. a) First, it generates a set of pipeline templates, a combination of which can utilize all available nodes. b) Then, pipelines are instantiated following the fastest plan after checking all possible plans. Credit: Insu Jang, University of Michigan As the demand for technologies that enable generative AI continues to skyrocket, processing capacities must keep pace to accommodate model training and fault tolerance. University of Michigan researchers designed a solution specific to modern AI workloads. A research team developed Oobleck, an open-source large-model training framework, using the concept of pipeline templates to provide fast and guaranteed fault recovery without training throughput degradation. The results were presented in October 2023 in the Proceedings of the 29th Symposium on Operating Systems Principles in Koblenz, Germany. \"Oobleck is a general-purpose solution to add efficient resilience to any large model pre-training. As a result, its impact will be felt in foundation model pre-training for the entire range of their applications from big tech and high-performance computing to science and medical fields,\" said Mosharaf Chowdhury, an associate professor of electrical engineering and computer science and corresponding author of the paper. Large language models require massive GPU clusters for large durations during pre-training, and the likelihood of experiencing failures increases with the training's scale and duration. When failures do occur, the synchronous nature of large language model pre-training amplifies the issue as all participating GPUs idle until the failure is resolved. Existing frameworks have little systemic support for fault tolerance during large language model pre-training. Current solutions rely on checkpointing or recomputation to recover from failures, but both methods are time-consuming and cause cluster-wide idleness during recovery with no formal guarantees of fault tolerance. Pipeline templates are at the core of Oobleck's design. A pipeline template, a specification of training pipeline execution for a given number of nodes, is used to instantiate pipeline replicas. All pipeline templates are logically equivalent (i.e., can be used together to train the same model) but physically heterogeneous (i.e., use different numbers of nodes). \"Oobleck is the first work that exploits inherent redundancy in large language models for fault tolerance while combining pre-generated heterogeneous templates. Together, this framework provides high throughput with maximum utilization, guaranteed fault tolerance, and fast recovery without the overheads of checkpointing- or recomputation-based approaches,\" said Insu Jang, a doctoral student in computer science and engineering and first author of the paper. Given a training job starting with the number of maximum simultaneous failures to tolerate, f, Oobleck's execution engine instantiates at least f + 1 heterogeneous pipeline from the generated set of templates. The fixed global batch is distributed proportionally to the computing capability of pipeline replicas to avoid having stragglers in training synchronization. Upon failures, Oobleck simply re-instantiates pipelines from the precomputed pipeline templates, avoiding the demanding analysis of finding a new optimal configuration at runtime. It is provably guaranteed that using the precomputed set of pipeline templates always enables Oobleck to recover from f or fewer failures. Resilience to unpredictable events is a classic problem in computer science. Instead of addressing problems after they happen, which is slow, or planning for all possible scenarios, which is practically impossible, pipeline templates strike a balance between speed and effectiveness in resilient distributed computing. \"Oobleck gives the first demonstration of the effectiveness of this idea, but it can potentially be applied to any distributed computing system where the same dichotomy exists. Going forward, we want to apply pipeline templates to improve the resilience of all facets of GenAI applications, starting with inference serving systems,\" said Chowdhury. Oobleck is open-source and available on GitHub . More information: Insu Jang et al, Oobleck: Resilient Distributed Training of Large Models Using Pipeline Templates, Proceedings of the 29th Symposium on Operating Systems Principles (2023). DOI: 10.1145/3600006.3613152 Provided by University of Michigan College of Engineering Citation : Open-source training framework increases the speed of large language model pre-training when failures arise (2023, December 18) retrieved 22 December 2023 from https://techxplore.com/news/2023-12-open-source-framework-large-language-pre-training.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "Data poisoning: How artists are sabotaging AI to take revenge on image generators",
  #     "topic": "Generative AI",
  #     "source": "Techxplore",
  #     "source_url": "Techxplore.com",
  #     "article_url": "https://techxplore.com/news/2023-12-poisoning-artists-sabotaging-ai-revenge.html",
  #     "publish_date": "18-12-2023",
  #     "content": "Credit: Unsplash/CC0 Public Domain Imagine this. You need an image of a balloon for a work presentation and turn to a text-to-image generator, like Midjourney or DALL-E, to create a suitable image. You enter the prompt: \"Red balloon against a blue sky,\" but the generator returns an image of an egg instead. You try again, but this time, the generator shows an image of a watermelon. What's going on? The generator you're using may have been \"poisoned.\" What is 'data poisoning'? Text-to-image generators work by being trained on large datasets that include millions or billions of images. Some generators, like those offered by Adobe or Getty, are only trained with images the generator's maker owns or has a license to use. But other generators have been trained by indiscriminately scraping online images, many of which may be under copyright. This has led to a slew of copyright infringement cases where artists have accused big tech companies of stealing and profiting from their work. This is also where the idea of \"poison\" comes in. Researchers who want to empower individual artists have recently created a tool named \" Nightshade \" to fight back against unauthorized image scraping. The tool works by subtly altering an image's pixels in a way that wreaks havoc to computer vision but leaves the image unaltered to a human's eyes. If an organization then scrapes one of these images to train a future AI model, its data pool becomes \"poisoned\". This can result in the algorithm mistakenly learning to classify an image as something a human would visually know to be untrue. As a result, the generator can start returning unpredictable and unintended results. Symptoms of poisoning As in our earlier example, a balloon might become an egg. A request for an image in the style of Monet might instead return an image in the style of Picasso. Some of the issues with earlier AI models, such as trouble accurately rendering hands, for example, could return. The models could also introduce other odd and illogical features to images\u2014think six-legged dogs or deformed couches. The higher the number of \"poisoned\" images in the training data, the greater the disruption. Because of how generative AI works, the damage from \"poisoned\" images also affects related prompt keywords. For example, if a \"poisoned\" image of a Ferrari is used in training data , prompt results for other car brands and for other related terms, such as vehicle and automobile, can also be affected. Nightshade's developer hopes the tool will make big tech companies more respectful of copyright, but it's also possible users could abuse the tool and intentionally upload \"poisoned\" images to generators to try and disrupt their services. Is there an antidote? In response, stakeholders have proposed a range of technological and human solutions. The most obvious is paying greater attention to where input data are coming from and how they can be used. Doing so would result in less indiscriminate data harvesting. This approach does challenge a common belief among computer scientists: that data found online can be used for any purpose they see fit. Other technological fixes also include the use of \" ensemble modeling \" where different models are trained on many different subsets of data and compared to locate specific outliers. This approach can be used not only for training but also to detect and discard suspected \"poisoned\" images. Audits are another option. One audit approach involves developing a \"test battery\"\u2014a small, highly curated, and well-labeled dataset\u2014using \"hold-out\" data that are never used for training. This dataset can then be used to examine the model's accuracy. Strategies against technology So-called \"adversarial approaches\" (those that degrade, deny, deceive, or manipulate AI systems), including data poisoning, are nothing new. They have also historically included using make-up and costumes to circumvent facial recognition systems. Human rights activists, for example, have been concerned for some time about the indiscriminate use of machine vision in wider society. This concern is particularly acute concerning facial recognition. Systems like Clearview AI , which hosts a massive searchable database of faces scraped from the internet, are used by law enforcement and government agencies worldwide. In 2021, Australia's government determined Clearview AI breached the privacy of Australians . In response to facial recognition systems being used to profile specific individuals, including legitimate protesters, artists devised adversarial make-up patterns of jagged lines and asymmetric curves that prevent surveillance systems from accurately identifying them. There is a clear connection between these cases and the issue of data poisoning, as both relate to larger questions around technological governance. Many technology vendors will consider data poisoning a pesky issue to be fixed with technological solutions. However, it may be better to see data poisoning as an innovative solution to an intrusion on the fundamental moral rights of artists and users. Provided by The Conversation This article is republished from The Conversation under a Creative Commons license. Read the original article . Citation : Data poisoning: How artists are sabotaging AI to take revenge on image generators (2023, December 18) retrieved 22 December 2023 from https://techxplore.com/news/2023-12-poisoning-artists-sabotaging-ai-revenge.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "Researchers use environmental justice questions to reveal geographic biases in ChatGPT",
  #     "topic": "Generative AI",
  #     "source": "Techxplore",
  #     "source_url": "Techxplore.com",
  #     "article_url": "https://techxplore.com/news/2023-12-environmental-justice-reveal-geographic-biases.html",
  #     "publish_date": "16-12-2023",
  #     "content": "A U.S. map shows counties where residents could (blue) or could not (pink) receive local-specific information about environmental justice issues. Credit: Junghwan Kim. Virginia Tech researchers have discovered limitations in ChatGPT's capacity to provide location-specific information about environmental justice issues. Their findings, published in the journal Telematics and Informatics , suggest the potential for geographic biases existing in current generative artificial intelligence (AI) models. ChatGPT is a large-language model developed by OpenAI Inc., an artificial intelligence research organization. ChatGPT is designed to understand questions and generate text responses based on requests from users. The technology has a wide range of applications from content creation and information gathering to data analysis and language translation. A county-by-county overview \"As a geographer and geospatial data scientist, generative AI is a tool with powerful potential,\" said Assistant Professor Junghwan Kim of the College of Natural Resources and Environment. \"At the same time, we need to investigate the limitations of the technology to ensure that future developers recognize the possibilities of biases. That was the driving motivation of this research.\" Utilizing a list of the 3,108 counties in the contiguous United States, the research group asked the ChatGPT interface to answer a prompt asking about the environmental justice issues in each county. The researchers selected environmental justice as a topic to expand the range of questions typically used to test the performance of generative AI tools. Asking questions by county allowed the researchers to measure ChatGPT responses against sociodemographic considerations such as population density and median household income. Key findings indicate limitations Surveying counties with populations as varied as Los Angeles County, California, with a population of 10,019,635, and Loving County, Texas, with a population of 83, the generative AI tool showed a capacity to identify location-specific environmental justice challenges in large, high-density population areas. However, the tool was limited in its ability to identify and provide contextualized information on local environmental justice issues. ChatGPT was able to provide location-specific information about environmental justice issues for just 515 of the 3018 counties entered, or 17 percent. In rural states such as Idaho and New Hampshire, more than 90 percent of the population lived in counties that could not receive local-specific information. In states with larger urban populations such as Delaware or California, fewer than 1 percent of the population lived in counties that cannot receive specific information. Impacts for AI developers and users With generative AI emerging as a new gateway tool for gaining information, the testing of potential biases in modeling outputs is an important part of improving programs such as ChatGPT. \"While more study is needed, our findings reveal that geographic biases currently exist in the ChatGPT model,\" said Kim, who teaches in the Department of Geography. \"This is a starting point to investigate how programmers and AI developers might be able to anticipate and mitigate the disparity of information between big and small cities, between urban and rural environments.\" Kim has previously published a paper on how ChatGPT understands transportation issues and solutions in the U.S. and Canada. His Smart Cities for Good research group explores the use of geospatial data science methods and technology to solve urban social and environmental challenges. Enhancing future capabilities of the tools Assistant Professor Ismini Lourentzou of the College of Engineering, a co-author on the paper, cited three areas of further research for large-language models such as ChatGPT: Refine localized and contextually grounded knowledge, so that geographical biases are reduced Safeguard large-language models such as ChatGPT against challenging scenarios such as ambiguous user instructions or feedback Enhance user awareness and policy so that people are better informed of the strengths and weaknesses, particularly around sensitive topics \"There are a lot of issues with the reliability and resiliency of large-language models,\" said Lourentzou, who teaches in the Department of Computer Science and is an affiliate of the Sanghani Center for Artificial Intelligence and Data Analytics. \"I hope our research can guide further research on enhancing the capabilities of ChatGPT and other models.\" More information: Junghwan Kim et al, Exploring the limitations in how ChatGPT introduces environmental justice issues in the United States: A case study of 3,108 counties, Telematics and Informatics (2023). DOI: 10.1016/j.tele.2023.102085 Provided by Virginia Tech Citation : Researchers use environmental justice questions to reveal geographic biases in ChatGPT (2023, December 16) retrieved 22 December 2023 from https://techxplore.com/news/2023-12-environmental-justice-reveal-geographic-biases.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "Apple research reveals some dazzling AI tech could be headed to your iPhone",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/apple-research-reveals-some-dazzling-ai-tech-headed-to-your-iphone/",
  #     "publish_date": "22-12-2023",
  #     "content": "June Wan/ZDNET Apple is taking a deep dive into artificial intelligence technology, according to two recently published research papers showcasing the company's work. The research shows Apple is working to develop on-device AI tech, including a groundbreaking method to create animatable avatars and a novel way to run large language models from an iPhone or iPad. Also: Do companies have ethical guidelines for AI use? 56% of professionals are unsure, survey says Aptly named \" LLM in a flash ,\" Apple's research on efficiently running LLMs on devices with limited memory enables complex AI applications to run smoothly on iPhones or iPads. This could also involve running a generative-AI-powered Siri on-device that simultaneously assists with various tasks, generates text, and features an improved ability to process natural language. HUGS stands for Human Gaussian Splats, a method to create fully animatable avatars from short video clips captured on an iPhone in as little as 30 minutes. HUGS is a neural rendering framework capable of training with as little as a few seconds of video to create a detailed avatar that users can animate however they'd like. What this means for the iPhone and Vision Pro There have been reports about Apple working on its own AI chatbot , used internally and called 'Apple GPT.' The new research shows that the company is making strides in running LLMs by leveraging flash memory on smaller, less powerful devices like an iPhone. This could make sophisticated generative AI tools available on-device and could mean a generative AI-powered Siri. Also: Microsoft Copilot can write songs for you now. Here's how to try it Beyond Siri's much-needed improvement, having an efficient LLM inference strategy like the one described in LLM in a Flash could lead to more accessible generative AI tools, significant advancements in mobile technology, and improved performance in a wide range of applications on everyday devices. Arguably the biggest advancement of the two, HUGS is a method that can create malleable digital avatars from just a few seconds of monocular video, or 50-100 frames, to be exact. These human avatars can be animated and placed on different scenes, as the platform uses a disentangled representation of humans and scenes. HUGS lets users create avatars of themselves that can be animated and placed on a scene. This is Apple's example of three avatars animated in sync. Apple According to Apple, HUGS outperforms competitors at animating human avatars with rendering speeds 100 times faster than previous methods and with a significantly shorter training time of only 30 minutes. Creating an avatar by leveraging the iPhone's camera and processing power could deliver a new level of personalization and realism for iPhone users in social media, gaming, educational, and augmented reality (AR) applications. HUGS could seriously reduce the creep factor for the Apple Vision Pro's Digital Persona , showcased during the company's last Worldwide Developers' Conference (WWDC) last June. Vision Pro users could wield the power of HUGS to create a highly realistic avatar that can move fluidly with a 60fps rendering time. Also: Apple's Vision Pro may launch in February - with its most sophisticated buying process yet The speed of HUGS would also allow for real-time rendering, which can be crucial for a smooth AR experience and could enhance social, gaming, and professional applications with realistic, user-controlled avatars. Apple tends to shy away from using buzzwords like 'AI' to describe its product features, preferring to focus on machine learning instead. However, these research papers suggest a deeper involvement in new AI tech. Still, Apple hasn't publicly acknowledged implementing generative AI into its products and has yet tto confirm its work with Apple GPT officially Artificial Intelligence AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "What developers trying out Google Gemini should know about their data",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/what-developers-trying-out-google-gemini-should-know-about-their-data/",
  #     "publish_date": "22-12-2023",
  #     "content": "Omar Marques/SOPA Images/LightRocket via Getty Images Developers who have jumped in to try out Google Gemini for free should know their data might be used to train its generative artificial intelligence (AI) models, including those that power Google AI Studio and Gemini Pro . The tech giant last week made Gemini Pro available to developers and businesses that are keen to build their own applications using its generative AI model. Developers can access the model via the Gemini API in Google AI Studio, while organizations will have to do so via Google Cloud's machine learning and development platform, Vertex AI . Also: AI will change the role of developers forever, but leaders say that's good news Developers currently have free access to Gemini Pro and Gemini Pro Vision, capped at 60 requests per minute, which Google said is suitable for most app development requirements. The Gemini Pro Vision model allows text and imagery to be accepted as input, although output remains as text. Vertex AI developers can trial both AI models, within the same cap, for free until general availability, which is expected to be early 2024. Also: How to use ChatGPT to write code Following this date, charges per 1,000 characters or per image will apply across Google AI Studio and Vertex AI. Google said it had cut prices fourfold on input and twofold on output. Gemini Pro supports 38 languages and is available across more than 180 markets, including the Asia-Pacific region. Developers can move their AI Studio code to Vertex AI if they want a fully managed AI platform that offers more customization and Google Cloud features, including data governance and compliance, and security. Google, though, is touting AI Studio as the fastest way to build using Gemini . Developers should note that when they use the free quota of 60 requests per minute, their API and Google AI Studio input and output \"may be accessible to trained reviewers\". Also: Generative AI means more productivity, and a likely retrenchment for software developers Google told ZDNET that it uses the API inputs and outputs to improve product quality. \"Human review is a necessary step of the model improvement process,\" a spokesperson said. \"Through review and annotation, trained reviewers help enable quality improvements of generative machine-learning models like the ones that power Google AI Studio and the Gemini Pro via the Gemini API.\" To protect developers' privacy, Google said their data is de-identified and disassociated from their API key and Google account, which is needed to log in to Google AI Studio. This protection takes place done before the reviewers can see or annotate the data. Also: AI in 2023: A year of breakthroughs that left no human thing unchanged Google's Terms of Service (ToS) for its generative AI APIs further states that the data is used to \"tune models\" and may be retained in connection to the user's tuned models \"[for] re-tuning when supported models change\". The ToS states: \"When you delete a tuned model, the related tuning data is also deleted.\" The terms also state that users should not submit sensitive, confidential, or personal data to the AI models. Data generated from when developers use Gemini Pro via Google AI Studio might still be accessed by Google reviewers, even if the developers make the move to Vertex AI. The data generated while users were on Google AI Studio will be tapped to help improve products, the Google spokesperson told ZDNET. \"This includes further model tuning and evaluations. We may also derive product insights from anonymized data to help us determine new features we want to explore adding to Google AI Studio,\" they said. Also: These 5 major tech advances of 2023 were the biggest game-changers Developers and organizations with concerns about data security, but who are still keen to build with Gemini, will probably want to do so as Google Cloud customers, as this route will give them access to Vertex AI. Google has assured that this pathway provides \"customization of Gemini with full data control\". Accessing Gemini models via Vertex Ai also allows enterprise customers to tune the models with their own data. In addition, Google says it does not train its generative AI models on inputs or outputs from its cloud customers. Artificial Intelligence AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "Microsoft Copilot can write songs for you now. Here's how to try it",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/microsoft-copilot-can-now-write-songs-for-you-heres-how-to-try-it/",
  #     "publish_date": "20-12-2023",
  #     "content": "screenshot by Lance Whitney/ZDNET Microsoft's AI-powered Copilot can now act as your personal song writer by creating songs based on your requests. In a blog post published Wednesday , Microsoft revealed Copilot's new skills as a composer courtesy of a third-party plug-in called Suno , an AI-based music generator. Also: Windows 12 FAQ: Yes, it's coming in 2024 (and more surprising predictions) With the plug-in enabled, you describe the subject of the song and the style or genre at the prompt. In response, Copilot writes and displays the lyrics and offers a Play button for you to hear its musical masterpiece. As a few examples, ask it to compose a country music song about two turtles who fall in love or a jazz song about a man getting a haircut or a rap song about a robot learning to be human. The lyrics appear fairly quickly, but you may need to wait a while for the song itself to generate depending on the lyrics and style. After the music is ready, you can play it and share it via email or social media. How to try it To give it a shot, open Microsoft Edge and browse to the Copilot website . Click the heading for Plugins at the right and turn on the one for Suno if it's not already on. Alternatively, click the Suno logo that says: \"Make music with Suno.\" Type your request at the prompt, and the response is slowly generated. When the image for your music appears, click the Play button to give it a listen. I tried a few prompts asking Copilot to compose tunes in different styles and on different subjects. Though the results wouldn't win any Grammys, they did show a certain flair and were especially adept at capturing the style of music I specified. Also: ZDNET looks back on tech in 2023, and looks ahead to 2024 With the progress being made in generative AI , more tools have been popping up that can create images, videos, and music based on your text descriptions. Using the Suno plug-in, Microsoft Copilot joins other current and upcoming AI-enabled music creation tools, including Google's MusicLM , Meta's AudioCraft , and Stability AI's Stable Audio . \"You don't have to know how to sing, play an instrument, or read music to bring your musical ideas to life,\" Microsoft said in its blog post. \"Microsoft Copilot and Suno will do all the hard work for you, matching the song to cues in your prompt. We believe that this partnership will open new horizons for creativity and fun, making music creation accessible to everyone.\" Featured Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "The best Samsung Galaxy phones you can buy (including foldables)",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/best-samsung-phone/",
  #     "publish_date": "20-12-2023",
  #     "content": "Of all the phone manufacturers, Samsung's lineup of handsets may be the most robust. Want a phone that has a built-in stylus? You've got that. Want a phone that can expand into a tablet? You've got that. too. Want a phone that you can go swimming with? Read on. That is to say, finding the best Samsung phone for you boils down to your personal needs, use cases, and design preferences. The freedom of choice here is particularly useful during the holiday shopping season, whether you're buying for that relative who wants a phone that \"just works\" or you're looking to upgrade to something with more technical prowess. To make the shopping process easy, I've personally tested most -- if not all -- the latest Galaxy phones that Samsung has to offer and assembled a catalog of the top options for your choosing, including the more recent Galaxy Z Flip and Z Fold series, the value-driven A-series, and my top pick right now, the Samsung Galaxy S23 Ultra . Also: The best Android phones you can buy right now (including flipping foldables) The best Samsung phones in 2023 Samsung Galaxy S23 Ultra Best Samsung phone overall June Wan/ZDNET Pros & Cons Pros Most complete smartphone experience money can buy Reliable quad-camera setup 256GB base storage leads the competition Integrated S Pen stylus for enhanced functionality Cons Phone can be unwieldy for some, especially with a case Fast charging is still capped at 45W Pricier than most Android phones More Details Samsung Galaxy S23 Ultra tech specs: Processor: Qualcomm Snapdragon 8 Gen 2 for Galaxy | Display: 6.8 inches | RAM / Storage Options: 12GB RAM with 256GB/512GB/1TB | Rear cameras: 200MP main, 12MP ultrawide, 10MP 10x optical, 10MP 3x optical | Battery : 5,000mAh In the grand calculus of the Samsung multiverse, the Galaxy S23 Ultra reigns supreme. It's arguably the most fully loaded smartphone that you can buy on the market, let alone from Samsung, which puts it at the top spot on our list. The Galaxy S23 Ultra comes with a large 6.8-inch AMOLED display, a beefy 5,000mAh battery that can last you as long as two days, a customized Snapdragon 8 Gen 2 for Galaxy processor to keep things running efficiently, and the sacred Samsung S Pen -- ideal for jotting down notes, graphics designing, or even signing PDFs. Review: Samsung Galaxy S23 Ultra I tested the Galaxy S23 Ultra earlier this year and called it \"one of the most complete handsets you can buy this year -- whether you like and need the excessive amount of features or not.\" Being the latest and greatest also means that the S23 Ultra comes equipped with Samsung's newest advancements in camera technology, including a 200-megapixel main lens that's capable of capturing the highest-resolution images we've seen on any Galaxy phone. There's also 8K video recording at 30 frames per second if you're into that. All this is to say that the Galaxy S23 Ultra is our pick for the best Samsung phone overall. View now at Samsung View now at Best Buy View now at Amazon more buying choices Samsung Galaxy S23 Plus Best Samsung phone for most people Jason Cipriani/ZDNET Pros & Cons Pros More wieldy 6.6-inch display Snappy performance with an Ultra-level processor Excellent battery life Cons Samsung's software can be overbearing Selfie camera smoothening is aggressive More Details Samsung Galaxy S23 Plus tech specs: Processor: Qualcomm Snapdragon 8 Gen 2 for Galaxy | Display: 6.6 inches | RAM / Storage: 8GB RAM with 256GB/512TB | Rear cameras: 50MP main, 12MP ultrawide, 10MP telephoto| Battery : 4,700mAh Samsung's Galaxy S23 Plus is not as flashy as its Ultra sibling but remains a formidable pick-up for shoppers eyeing a meaningful upgrade. In fact, the core experience of the Ultra model is present on the Plus, including the OneUI software, Qualcomm Snapdragon 8 Gen 2 for Galaxy chipset, 256GB of base storage, and a flexible camera system. I'd argue that the Plus-sized Galaxy S23, in some ways, is an even better phone to buy for some users. For example, it has a slightly smaller 6.6-inch display that makes it easier to manage with one hand, the panel is flat along the edges so it's less susceptible to damage (and easier to repair), and the camera system doesn't look like a tarantula staring back at you. Review: Samsung Galaxy S23 Plus Alright, that last point might not be the best reason to buy the Plus model over the Ultra, but perhaps the $200 price difference is. At a starting price of $999 -- less if you wait for the holiday shopping season right around the corner -- the S23 Plus is the best Samsung phone for those who can live without all the Galaxy bells and whistles. And according to ZDNET reviewer, Jason Cipriani, \"as far as the S23 Plus is concerned, you're getting your money's worth.\" View now at Samsung View now at Best Buy View now at Walmart more buying choices Samsung Galaxy Z Fold 5 Best Samsung foldable phone June Wan/ZDNET Pros & Cons Pros An innovative gapless folding design Armor Aluminum material for a lighter and sleeker phone High IPX8 water resistance S Pen support Improved processor and software optimized for foldables Cons Still expensive, but generous trade-in offers abound S Pen purchase and store separately More Details Samsung Galaxy Z Fold 5 tech specs: Processor: Qualcomm Snapdragon 8 Gen 2 | Main display: 7.6 inches | Cover display: 6.2 inches | RAM/Storage: 12GB RAM with 256GB/512GB/1TB internal options | Cameras: 12MP ultrawide, 50MP wide angle, 10MP 3x telephoto, 10MP cover screen, 4MP under main display | Battery: 4,400mAh The 2020 Galaxy Z Fold 2 set the bar for foldable devices that also serve as mini tablets. The Z Fold 3 improved on that phone with two of the most highly requested features from Fold users (S Pen support and IPX8 water resistance), while the Z Fold 4 improved the rear cameras and form factor of the phone. And now, with the Z Fold 5, you'll get an upgraded processor in the Qualcomm Snapdragon 8 Gen 2, which should improve the phone's overall performance, from battery efficiency to camera capture. This year's model is also notably thinner than the last, and thanks to the no-gap hinge mechanism, ZDNET's Jason Hiner said in his review that \"the Fold 5 feels like the way foldables always should have been.\" Review: Samsung Galaxy Z Fold 5 The Android 13 software found in the Z Fold 5 gives the phone some serious productivity upgrades, especially in terms of multi-app usage thanks to the improved Taskbar and wider support for gesture navigations that ease the transition from multiple active windows. Like the Z Fold 4, the Fold 5's cameras are not quite as good as the S23 Ultra's suite, but the hardware is clearly superior to any foldable predecessor, and the competition . And it certainly helps that the Z Fold 5 is not as heavy and bulky as its predecessors. View now at Amazon Samsung Galaxy Z Flip 5 Best compact Samsung phone June Wan/ZDNET Pros & Cons Pros High-quality materials, fit, and finish IPX8 water resistance Larger external display is game-changing The most pocketable Galaxy phone yet Cons No telephoto camera Battery is reasonably underwhelming compared to larger phones More Details Samsung Galaxy Z Flip 5 tech specs: Processor: Qualcomm Snapdragon 8 Gen 2 | Main display: 6.7 inches | Cover display: 3.4 inches | RAM/Storage: 8GB RAM with 256GB/512GB internal options | Cameras: Two rear 12MP, 10MP selfie | Battery: 3,700mAh While the Z Fold 5 is the best Samsung foldable, it's the new Z Flip 5 that will likely sell the most and appeal to the masses. Not only is the clamshell handset less expensive than the Z Fold, but it's more compact and portable and has a more user-friendly learning curve. Shape-shifting displays aside, the Z Flip 5 is very similar to the standard Samsung Galaxy S-series flagship, with a large 6.7-inch AMOLED panel that's crisp and bright, up to 512GB of RAM for those high-resolution pictures and videos, and a healthy 3,700mAh cell powering it all. Review: Samsung Galaxy Z Flip 5 I tested the flip phone for weeks and was left impressed by how many refinements Samsung had made when compared to the last-gen Z Flip. Thanks to the new 3.4-inch outer display, the gapless hinge design, and improved durability, I noted in my full review that \"unless Samsung unveils some form of XR headset later this year, the Z Flip 5 is without question the company's most ambitious product of 2023.\" Folks who thrive in social media and content creation especially will love the Z Flip 5's ability to switch between shooting styles like camcorder mode and flex mode , much like its predecessor, the Z Flip 4. The camera system on this is not on the level of Samsung's Ultra and Plus phones, but it's reliable enough for everyday captures. View now at Samsung View now at Amazon View now at Walmart more buying choices Samsung Galaxy A54 5G Best Samsung phone under $450 June Wan/ZDNET Pros & Cons Pros Price is more than reasonable A 'jack of all trades, master of none' smartphone Reliable 5,000mAh battery Up to five years of software and security updates Cons Low-band 5G support Plasticky build quality Cameras are not as capable as flagships More Details Samsung Galaxy A54 5G tech specs: Processor: Samsung Exynos 1380 | Display: 6.4 inches| RAM/Storage: 6GB/128GB | Cameras: 50MP wide, 12MP ultrawide, 5MP macro, and 32MP front-facing camera | Battery: 5,000mAh While the flagship Galaxy S and Z fold series provide compelling options, they are flagship phones priced in the $900 and higher range. To offer customers another alternative, Samsung created the Galaxy A series, led by none other than the A54 5G. There are three key reasons why you should buy the Galaxy A54 5G over any other sub-$500 phone: For $449, you get a fantastic 6.4-inch AMOLED display that ramps up to 120Hz refresh rate, a triple-camera setup that includes a 50MP main sensor, and a beefy 5,000mAh battery. Review: Samsung Galaxy A54 5G Clearly, Samsung knows what features users value the most, and if you have preferences beyond that list, then there are plenty of other picks above and below. The A-series of smartphones also fall under Samsung's five-year commitment to software and security updates, which is rare for devices in this price range. As I put it in my review of the device, \"This $450 phone absolutely nails the essentials -- things like a large display that feels as smooth as it looks, battery life that lasts, and software stability that similarly-priced phones simply can't match.\" View now at Amazon View now at Samsung View now at Best Buy more buying choices Samsung Galaxy A14 5G Best cheap Samsung phone Samsung/ZDNET Pros & Cons Pros Affordably priced and available unlocked Large 6.6-inch display with all-day battery life Extensive software support Cons Plastic build is not for all Macro and depth cameras are unreliable Only one color option: Black More Details Samsung Galaxy A14 5G tech specs: Processor: Mediatek Dimensity 700 | Display: 6.6 inches| RAM/Storage: 4GB/64GB | Cameras: 50MP wide, 2MP macro, 2MP depth sensor, and 13MP front-facing camera | Battery: 5,000mAh The flashiest of smartphone features tend to exist only on flagships, but many will find appeal in Samsung's humble Galaxy A14 5G, which boasts 5G connectivity, a massive 5,000mAh battery, and a budget-friendly $200 price tag. That's a compelling new package at a time when consumers are cutting down on spending . And don't let the lower cost fool you; the Galaxy A14 5G has all the specs you'd want for a feasible mobile companion, from the relatively large 6.6-inch 90Hz display -- a rarity in this price range -- to the expandable storage (up to 1TB) to Samsung's four-year commitment to security patches. Oh, and the front-facing camera is higher resolution than ever for the selfie-lover in your life. I spent time with the A15 5G just a week ago as my partner was upgrading to the Z Flip 5 mentioned above. The phone won't feel like a million dollars, but it was surprisingly sturdy to hold -- devices in this price range tend to feel more hollow and toy-like -- and the 90Hz display looked great for app browsing and navigating around. Also: Samsung just launched its cheapest 5G Galaxy phone yet View now at Amazon View now at Best Buy View now at Walmart more buying choices What is the best Samsung phone? While the Samsung Galaxy S23 Ultra sits at the top of this year's ranking list, here's a wider scope of ZDNET's best picks and their respective feature sets. Samsung phone Price Display Cameras Battery Samsung Galaxy S23 Ultra 5G $1,199 6.8 inches 200MP wide, 10MP with 10x optical, 10MP with 3x optical, and 12MP ultrawide. 12MP front-facing camera 5,000mAh Samsung Galaxy S23 Plus $1,799 6.6 inches 50MP wide, 10MP with 3x optical, and 12MP ultrawide, 12MP front-facing camera 4,700mAh Samsung Galaxy Z Fold 5 $1,799 7.6 inches and 6.2 inches 50MP wide, 10MP with 3x optical, and 12MP ultrawide, 10MP cover screen, 4MP under main display 4,400mAh Samsung Galaxy Z Flip 5 $999 6.7 inches and 3.4 inches 12MP wide, 12MP ultrawide, 10MP front-facing camera 3,700mAh Samsung Galaxy A54 5G $449 6.4 inches 50MP wide, 12MP ultrawide, 5MP macro, and 32MP front-facing camera 5,000mAh Samsung Galaxy A14 5G $199 6.6 inches 50MP wide, 2MP macro, 2MP depth sensor, and 13MP front-facing camera 5,000mAh Which Samsung phone is right for you? It was much easier to choose a Samsung phone option in the past when just the S and Note series were available, along with some low-range, basic phones. Samsung has significantly expanded its offerings with the A Series, Fold, and Flip options. So, the first thing you should now consider is your desired form factor. First, decide if you want a standard \"glass rectangle\" smartphone or if you want a folding device. For maximum screen real estate, get a Z Fold 5. Or, for taking up the minimum space in your pocket and providing that extra bit of style, get a Z Flip 5 or Galaxy S23. With Samsung's current lineup, you have phones priced from under $200 to over $1,200. Your budget should quickly help you figure out which price point is right for you. From there, begin comparing individual features, like stylus support, or which device has the best camera array. Choose this Samsung phone... If you want... Samsung Galaxy S23 Ultra The top-of-the-line flagship Samsung phone with all the bells and whistles in a traditional form factor. It's pricier than most but is worth the money if you want a no-frills handset that can do just about everything. Samsung Galaxy S23 Plus A Galaxy phone capable of accomplishing 80% of what the Ultra model can do and costs less. The Galaxy S23 Plus is also slightly smaller, making it easier to manage. Samsung Galaxy Z Fold 5 A tablet/smartphone hybrid foldable and one of the most innovative Samsung devices available. It's arguably the best foldable phone on the market, too. Samsung Galaxy Z Flip 5 A stylish and pocket-friendly smartphone that doesn't compromise performance. If you're shopping for your first foldable phone, this is the best place to start. Samsung Galaxy A54 5G You're shopping on a $500 budget. Even then, you'll receive a generous suite of premium features like the 120Hz OLED display, triple-camera setup, and long-lasting battery. Samsung Galaxy A14 5G You're shopping on a $200 budget, but still want a good handset. It's difficult to impress in this price range, but the A14 5G gets the job done. How did I choose these Samsung phones? ZDNET writers spend upwards of months with every phone in this best list, while sourcing opinions and recommendations from industry experts and analysts who have also tested the devices. Here are the key factors that we look for when curating the top picks. Design : Unlike how we would compare the best Android phones , comparing Samsung phones across different price points mostly boils down to the hardware. How a phone is designed, what material choices the manufacturer makes, and whether or not the device can take a hit or two are considered when picking the very best. Cameras : The camera systems on Samsung phones have gotten really good over the past few years, so much so that you're well off even if you opt for a mid-ranger like the Galaxy A54 . Special features : If there's one thing that differentiates most Samsung phones from other manufacturers, it's unique features. From the S23 Ultra with its built-in stylus and 200MP camera to the foldable screens of the Z Fold and Z Flip, you'll feel a sense of wonderment when using something that's built differently. Availability : Samsung has a reputation for bringing the wildest phones to the press, even if they're not readily available. That's why, every pick on this list can be purchased at the time of writing, whether that's on Samsung's website or at a local carrier store. What is the newest Samsung phone? The newest Samsung phone is the Galaxy S23 FE , which features a Snapdragon 8 Gen 1 processor, a 6.4-inch Dynamic AMOLED display, and a triple camera system at the rear. What is Bixby on Samsung phones? Bixby was first introduced in the Galaxy S8 phones and, according to Samsung, is an \"intelligence assistant\" that can be activated by voice, taps, or text. Bixby is essentially Samsung's version of Siri and can perform the typical smart assistant functions like telling you the weather, translating text, and even controlling smart home appliances. Which Samsung phone has the best camera? The Samsung Galaxy S23 Ultra has the best camera of any Samsung phone and one of the best overall cameras on the phone market. It features a 200MP main camera along with four accompanying cameras, which allow it to take extremely high-quality shots including close-up images and ones that are ultrawide. The S23 Ultra can also video record in up to 8K UHD quality at 30fps, making it one of the most capable phone cameras money can buy. Which Samsung phone is the best value for money? There's beating around the Galaxy A54 5G and its wealth of flagship-killing features and specs. As flagship smartphones continue to creep up in price -- no thanks to inflation -- a $450 that does everyday tasks well is both a surprise and a blessing. As mentioned earlier, the value package of the A54 5G only looks better when you compare it to other smartphones in its price range, like the iPhone SE (2022) and now Google Pixel 7a. Are there alternative phones to consider? Be sure to check out ZDNET's comparisons of the best phones and Android phones available. We've also listed the top (non-Samsung) picks from both those guides below for your convenience. Best premium phone alternative Google Pixel 8 Pro The latest Pixel to hit the market, the Pixel 8 Pro delivers a familiar Google camera experience but now with enhanced generative AI features like Audio Magic Eraser, Magic Editor, and more. View at Amazon Best foldable alternative Motorola Razr Plus In many ways, the Motorola Razr Plus is superior to the Galaxy Z Flip 5, like the larger 3.6-inch external display and higher refresh rate panels. It also costs the same, making it a killer alternative. View at Amazon Best mid-range alternative Samsung Galaxy S23 FE The latest addition to the Galaxy S23 lineup, the FE offers flagship features at a more accessible price point. View at Samsung ZDNET Recommends The best smartwatches you can buy: Apple, Samsung, Google, and more compared The 5 best VPN services (and tips to choose the right one for you) The best Android phones you can buy (including a surprise pick) The best robot vacuum and mop combos (and if they're worth the money) The best smartwatches you can buy: Apple, Samsung, Google, and more compared The 5 best VPN services (and tips to choose the right one for you) The best Android phones you can buy (including a surprise pick) The best robot vacuum and mop combos (and if they're worth the money)",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "I went to Microsoft to talk about AI. I'm still a little startled (but hopeful too)",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/i-went-to-microsoft-to-talk-about-ai-im-still-a-little-startled-but-hopeful-too/",
  #     "publish_date": "20-12-2023",
  #     "content": "David Paul Morris/Bloomberg via Getty Images I was excited, of course. Earlier this year, Microsoft invited me to its Silicon Valley campus to contemplate AI, the generative kind . So there I was in this enormous, airy building of the future, with hardly a human being in sight. I wafted into a very fetching theater \u2013 yes, they spelled my name wrong on the big screen -- and there were several actual journalistic luminaries on stage too . Also: The future of generative AI: Here's what technology analysts are saying Oh, and a PR man from Microsoft, dressed all in black. The specific subject was AI and journalism. Little did I know how much it would move my whole year. For here I was, perhaps for the first time, confronted with the three great horsepersons of AI -- the Experimenters, the Fearful and the Capitulists. Those last ones? Capitalists who have already capitulated to AI's allegedly all-encompassing powers. Let's try something new Some panelists mused that the seemingly sudden incursion of AI offered a fine chance to dabble with it. At one news service, for example, they've experimented with an AI version of one of its sports editors. Also: ZDNET looks back on tech in 2023, and looks ahead to 2024 The idea is to put some text into this AI-generated expert and let it/them speak. Yes, but could this bot give us a decent betting line on the Niners vs the Cowboys? You have to find a balance, said the news service's journalist. But is there really any value added by being, well, so tech-clever? This seemed to me to be one of the currently less-considered questions about AI. The year was all about generative AI. But, as with quite a few tech breakthroughs, how useful (and profitable) will it ultimately be? And precisely where and how? So a strong impulse was to put it to the test in as many ways as possible. You never know what might emerge. Oh, AI. Who is the fairest of them all? You Are. But then there was the gentlefellow from another tech publication. I know that sounds like the beginning of a joke, but it truly isn't. It's more of a mood enhancer. Also: The future of work is more human than you'd think, say these business experts You see, this particular gentlefellow is an enormous enthusiast for AI. Actually, 'enthusiast' doesn't quite cover it. He seemed more like the mesmerized subject of a despotic kingdom. He offered the prediction that \"generative AI will touch every piece of every part of the process of news from ideation, to headline generation to story editing.\" Full disclosure: I had the idea for this column myself, my editor is a human being with infinite patience, and I'm writing with my own fingers and (what's left of my) mind. That's the thing with predictions. They don't always come true. Just ask any AI sports editor. I won't dwell on some of this nice man's more vivid admissions -- they've been covered elsewhere . For me, what was most affecting were these words: \"Frankly, I think that the AI model is always more clever than me because it includes all of the written text throughout all of history.\" I fear several things shot through my head at this very moment. No, of course 'How clever actually are you?' wasn't one of them. Also: The promise and peril of AI at work in 2024, according to Deloitte's Tech Trends report Not even when he said: \"It feels like it is so much more talented than I'll ever be.\" I met many people in college who'd read a lot of books. Seemingly every book that mattered. But would I have thought them clever or talented? Would I have imagined they'd, um, change the world? Not really. (Update: They didn't.) Let AI be AI but you do you I confess that night became my tech moment of the year. Everywhere I went I seemed to meet either experimenters, fearers or, indeed, capitulists. Both experimentation and fear are, of course, understandable. But to witness capitulism live on stage was a touch startling, and the feeling hasn't quite gone away. Also: AI in 2023: A year of breakthroughs that left no human thing unchanged I couldn't help offering a small retort to this committed AI capitulist. \"Maybe you should just believe in yourself more,\" I said. \"I'm really concerned about you. Is it possible that because of your enthusiasm, you're already abdicating your own talents? You're actually maybe better than you think.\" It kept on striking me throughout the year that for all the talk about the evil side of AI \u2013 and, because humans, there's plenty of evil \u2013 there's another side. The true fascination of generative AI doesn't necessarily lie in what it's going to do to us, or even for us. It's what we can do with it. It may actually show how clever we really are, not merely how clever we think we are. If the internet taught us anything \u2013 yes, I know the jury is still out \u2013 it's that we derived enormous benefits and created new ways of talking and being -- just as we endured awful changes of mood, behavior and hope. Isn't that likely with AI too? Also: Generative AI filled us with wonder in 2023 - but all magic comes with a price 2023 wasn't necessarily the year when AI began to take over our souls. It was merely a large new door opening, sucking us toward a blinding light. I feel an appropriate level of fear having experimented with ChatGPT , with both hilarious and freakish results. (Watching a deepfake version of someone you do business with is truly a mind-twisting experience.) But to be a capitulist strikes me as not merely defeatist, but just a little dull. Here's an oddly optimistic thought: AI, this clever and talented thing, might even help us slow down a little and think a little more. Also: Here's how to create your own custom chatbots using ChatGPT Oh, and here's another optimistic thought: We've just learned that AI can get tired and lazy \u2013 perhaps it's embracing the human condition in the same way that we're embracing the AI condition. After all, what can it do without our input? (Please don't answer that right now.) We won't know for sure, of course until, say, 2032. You may, of course, place your bets now with my personal AI Betbot service. Featured Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "Do companies have ethical guidelines for AI use? 56% of professionals are unsure, survey says",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/do-companies-have-ethical-guidelines-for-ai-use-56-of-professionals-are-unsure-survey-says/",
  #     "publish_date": "20-12-2023",
  #     "content": "Parradee Kietsirikul/Getty Images Although AI has been around since the 1950s, it has seen tremendous growth within the past year. Tech giants have been implementing AI into their products and services, while individuals are using it to make their lives a little easier . Deloitte surveyed companies and professionals in its second edition of the \"State of Ethics and Trust in Technology\" report, led by its Technology Trust Ethics practice. According to the report, 74% of companies have already begun testing generative AI, while 65% have begun to use it internally. The increasing awareness of AI's new capabilities has led to the pressing question of how organizations can use this technology ethically. Also: The ethics of generative AI: How we can harness this powerful technology Deloitte interviewed 26 specialists in various industries to gather information about how industry leaders are considering concerns about the ethical use of emerging technologies, including generative AI . The company then tested hypotheses and delivered a 64-question survey to more than 1,700 businesses and technical professionals to gain further insights. Special Feature The Future of AI, Jobs, and Automation We've entered a period of dramatic innovation in AI and automation and it's going to have a significant impact on the future of jobs, productivity, and the ways we operate in teams. Research predicts that worker productivity could increase by as much as 4x by 2030, powered by AI. We unpack the opportunities and the ways to benefit from this transformation. Read now The report, by Beena Ammanath, managing director of Deloitte Consulting LLP and leader of Deloitte's Technology Trust Ethics practice, refers to emerging technologies as the following: Cognitive technologies (including general and generative AI and chatbots), digital reality, ambient experiences, autonomous vehicles, quantum computing, distributed ledger technology, and robotics. According to the survey, 39% of survey respondents, consisting of business leaders and developers of emerging technologies, thought cognitive technologies had the most potential for social good, compared to 12% in digital reality, and 12% in ambient experiences. Also: 5 essential traits that tomorrow's AI leader must have However, 57% of survey respondents also thought that cognitive technologies had the greatest potential for serious ethical risk. The most concerning statistic is that over half of the respondents (56%) said their \"company does not have or are unsure if they have ethical principles guiding the use of generative AI.\" Deloitte Technology Trust Ethics Survey Compared to Deloitte's report in 2022 about ethics and trust in emerging technologies, this year's report reveals that \"organizations find themselves wrestling with new ethical issues posed by wide-scale adoption of this once-again new technology.\" These issues are tied to concerns about how businesses and organizations are using these technologies. Despite the many benefits of AI, 22% of respondents were concerned with data privacy while 14% cited transparency about how AI is trained with data to produce its outputs. Also: Does your business need a chief AI officer? Data poisoning as well as intellectual property and copyright were concerns that each consisted of 12% of survey respondents. Data poisoning is the \"pollution\" of data training sets by bad actors and can lead to inaccurate results produced by AI. Deloitte Technology Trust Ethics Survey Deloitte's report also detailed the types of damage that survey respondents believe could arise when ethical violations are not taken seriously. Reputational damage was the greatest source of concern coming from 38% of respondents, followed by human damage such as misdiagnoses or data privacy violations (27%), regulatory penalties like copyright infringement (17%), financial damage (9%), and employee dissatisfaction (9%). These damages are evident in the several lawsuits that have already been filed due to privacy violations , copyright infringement, and other issues related to the unethical use of AI. Also: AI and automation: Business leaders adopt small-scale solutions for greater impact So how can companies ensure they using AI safely? Deloitte lists a multi-step approach to helping companies: Exploration: Companies can begin by letting product owners, business leaders, and AI/ML practitioners explore generative AI through workshops to see how it could create value for their businesses. This way, companies can recognize the costs and benefits of incorporating AI into their businesses. Foundational: Companies could buy or build AI platforms to implement generative AI into their businesses. Of the survey respondents, 30% of survey respondents' companies chose to use existing capabilities with major AI platforms. 8% of respondents created their own in-house AI platforms, while 5% decided not to use generative AI. Governance: Creating standards and protocols for AI use could minimize the potentially harmful impacts of AI, so companies should determine what types of ethical principles they plan to uphold. Trainings and education: Companies could mandate trainings that outline the ethical principles of using AI. In addition, technical trainings that educate employees about using a variety of LLMs could provide companies with more guidance about the ethical use of AI. Pilots: Engineers and product leaders could run experiments on a variety of use cases to test proof of concepts and pilot programs and then eliminate aspects that are too risky. Implementation: Companies should draft a plan for introducing a newly enhanced product into the market and assign accountability for product implementation and ownership. The company should also have a team of experts prepared to address any issues that may arise. Transparency is also crucial for this step, as companies should explain how user data is inputted into the model, how the model reaches its output, and how likely the model is to hallucinate. Audit: According to one interviewee, companies will need to modify their policies depending on the risks of AI use. This could vary company by company, as not all organizations will incorporate AI for the same use case. In considering the impact of generative AI on human workers, issues such as transparency and data privacy ranked above job displacement. Nevertheless, the report also mentioned that \"49% said workers at their organization displaced by AI moved to different roles and retrained and upskilled.\" Furthermore, 11% were terminated, 13% were put in a different role without being retrained or upskilled, and 27% did not experience any job displacement at their organization from AI, according to Deloitte. Also: Will AI hurt or help workers? It's complicated \"The sooner companies work together to identify the risks and establish governance up front, the better their ability may be to help generate stakeholder value, elevate their brands, create new markets, and contribute to building a more equitable world,\" said Ammanath. Artificial Intelligence AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "The future of generative AI: Here's what technology analysts are saying",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/the-future-of-generative-ai-heres-what-technology-analysts-are-saying/",
  #     "publish_date": "20-12-2023",
  #     "content": "Artem Peretiatko/Getty Images According to 2023 research , most people are concerned about the implications of generative AI on data security, ethics, and bias. In fact, 81% of customers want a human to be in the loop, reviewing and validating generative AI outputs. A mere 37% of customers trust AI's outputs to be as accurate as those of an employee. The research found that the trust gap widens as AI goes mainstream. Brands are turning to generative AI to boost efficiency while improving customer engagement. Customers -- wary of the technology risks -- demand a thoughtful approach built on trust. Eighty percent of customers say it's important for humans to validate AI's outputs. Also: Two breakthroughs made 2023 tech's most innovative year in over a decade Demystifying AI could significantly reduce the fear surrounding it. If we can move AI from an opaque black box to a transparent glass cube, we can recalibrate how we adopt the technology. A strong argument can be made that every AI foundational model must have a FICO score . The latest State of IT 2023 Report by Salesforce, a survey of 4,300 IT decision-makers and leaders, found that 9 out of 10 CIOs believe generative AI has gone mainstream. The report found that AI and automation underpin efficiency and innovation. Process automation is on the rise as businesses tighten their belts and seek efficiency boosts, while advances in AI prompt IT to determine how -- not if -- to responsibly propel their organizations forward. Eighty-six percent of IT leaders believe generative AI will have a prominent role in their organizations in the near future. McKinsey's latest research estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases analyzed by McKinsey -- by comparison, the United Kingdom's entire GDP in 2021 was $3.1 trillion. https://t.co/CtEHUZXe1o pic.twitter.com/YLTMhPPN25 \u2014 Vala Afshar (@ValaAfshar) August 9, 2023 According to McKinsey , 50% of organizations used AI in 2022. IDC is forecasting global AI spending to increase a staggering 26.9% in 2023 alone. A recent survey of customer service professionals found adoption of AI had risen by 88% between 2020 and 2022. McKinsey's latest research estimates that generative AI could add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use cases. Generative AI will revolutionize the way we work. Also: AI in 2023: A year of breakthroughs that left no human thing unchanged AI is the electricity of the 21st century. Ignore it and your business will be left in the dark. After all, we already know many ways that generative AI will shape how we work . Research on generative AI's impact on the future of work reveals that AI has the potential to automate 40% of the average workday. Productivity gains from generative AI in marketing sees marketers saving one month a year. https://t.co/IAFuwJORWa \u2014 Vala Afshar (@ValaAfshar) August 10, 2023 A survey suggests AI has the potential to automate 40% of the average work day, according to research firm Valoir . The widespread use of generative artificial intelligence has raised public awareness of its ability to increase productivity and efficiency, as well as its risks. AI and automation propel efficiency and innovation. Salesforce So, what are the largest and most influential technology analyst firms saying about the impact of generative AI on the future of work and the enterprise? According to Gartner, generative AI will make an increasingly strong impact on enterprises over the next five years. Gartner predicts that: By 2024, 40% of enterprise applications will have embedded conversational AI, up from less than 5% in 2020. By 2025, 30% of enterprises will have implemented an AI-augmented development and testing strategy, up from 5% in 2021. By 2026, generative design AI will automate 60% of the design effort for new websites and mobile apps. By 2026, over 100 million humans will engage robocolleagues to contribute to their work. By 2027, nearly 15% of new applications will be automatically generated by AI without a human in the loop, which is not happening at all today. More than 55% of all data analysis by deep neural networks will occur at the point of capture in an edge system by 2025, up from less than 10% in 2021. The primary focus of generative AI initiatives. Gartner Generative AI is positioned on the Peak of Inflated Expectations on the Gartner Hype Cycle for Emerging Technologies, 2023 . Here are Gartner's top 10 strategic predictions : By 2027, the productivity value of AI will be recognized as a primary economic indicator of national power. By 2027, GenAI tools will be used to explain legacy business applications and create appropriate replacements, reducing modernization costs by 70%. By 2028, enterprise spending on battling malinformation will surpass $30 billion, cannibalizing 10% of marketing and cybersecurity budgets to combat a multifront threat. By 2027, 45% of chief information security officers (CISOs) will expand their remit beyond cybersecurity, due to increasing regulatory pressure and attack surface expansion. By 2028, the rate of unionization among knowledge workers will increase by 1,000%, motivated by the adoption of GenAI. In 2026, 30% of workers will leverage digital charisma filters to achieve previously unattainable advances in their careers. By 2027, 25% of Fortune 500 companies will actively recruit neurodivergent talent across conditions like autism, ADHD, and dyslexia to improve business performance. By 2028, there will be more smart robots than frontline workers in manufacturing, retail, and logistics due to labor shortages. By 2026, 50% of G20 members will experience monthly electricity rationing, turning energy-aware operations into either a competitive advantage or a major failure risk. By 2026, generative AI will significantly alter 70% of the design and development effort for new web applications and mobile apps. Generative AI is positioned on the Peak of Inflated Expectations on the Gartner, Inc. Hype Cycle for Emerging Technologies, 2023 . Gartner IDC believes that the tech industry is at a seminal moment. Never have we seen a technology emerge with this much executive support, clearly defined business outcomes, and rapid adoption. Also: These 5 major tech advances of 2023 were the biggest game-changers IDC has identified three broad types of generative AI use cases that need to be assessed that are industry specific, business function, and productivity-related. Generative AI: The path to impact. IDC IDC notes that the landscape of business may be seeing a seismic shift with the rise of generative AI. IDC advises business leaders to start with the following solid foundation: Responsible AI policy: A well-defined AI policy that outlines principles of fairness, transparency, accountability, and data protection is paramount. AI strategy and roadmap and the role of the proof of concept: The AI strategy should include the rules or guidelines for generative AI proofs of concept (POCs), and it should incorporate the results of the POCs to recursively improve the strategy. Intelligent architecture: Data privacy, security, and intellectual property protection must also be embedded within this platform architecture. Reskilling and training: Most organizations do not have mature skill sets (prompt engineering, data science, data analysis, AI ethics, modeling) required to take full advantage of generative AI. IDC also notes that data serves as the foundation for generative AI. When IDC surveyed clients about their data, troubling results were revealed. 82% of organizations report siloed data ( Future Enterprise Resiliency & Spending Survey ). 41% cite that data is changing faster than they can keep up with ( Global Data Valuation Survey ). 24% do not trust their data ( Future Enterprise Resiliency & Spending Survey ). 29% have issues with data quality ( Future Enterprise Resiliency & Spending Survey ). By 2025, according to IDC, organizations will allocate over 40% of their core IT spend to AI-related initiatives, leading to a double-digit increase in the rate of product and process innovations. AI will radically reshape IT , according to IDC. Code generation, enterprise content management, marketing, and customer experience applications are some of the key areas for generative AI use cases in the enterprise , per IDC. IDC forecasts enterprise spending on GenAI services, software and infrastructure will grow from $16 billion in 2023 to $143 billion in 2027. Spending on generative AI over the four-year period to 2027 is expected to reach a compound annual growth rate (CAGR) of 73.3%. 2023 STATE OF IT REPORT 20 key IT statistics and trends found that every CIO should know: 1. 84% of IT leaders say their departments need to better address changing customer expectations. 2. 82% of IT leaders say their departments need to better demonstrate business\u2026 \u2014 Vala Afshar (@ValaAfshar) September 5, 2023 Forrester research points to the next generation of modern software development, where generative AI TuringBots speed and improve software development. Forrester defines TuringBots as: AI-powered software that augments application development and infrastructure and operations teams' automation and semiautonomous capabilities to plan, analyze, design, code, test, deliver, and deploy while providing assistive intelligence on code, development processes, and applications. Also: Today's AI boom will amplify social problems if we don't act now, says AI ethicist Forrester predicts that TuringBots will write 10% of worldwide code and tests. Here are additional Forrester generative AI predictions for the enterprise: One in four tech execs will report to their board on AI governance. Forrester's data shows that 46% of data and analytics business and technology decision-makers seek out partners to implement AI that's critical to the business. Ten percent of Fortune 500 enterprises will generate content with AI tools. Generative AI TuringBots improve software development. Forrester Forrester predicts that Generative AI will be the fulcrum that businesses rely on to enhance, empower, and engage employees and customers -- with or without you. Forrester's predictions on AI include: Generative AI will seep into consumers' lives. Sixty percent of skeptics will use (and love) generative AI -- knowing it or not. AI will spur the age of creativity. Enterprise AI initiatives will boost productivity and creative problem-solving by 50%. Current AI projects already cite improvements of up to 40% in software development tasks. GenAI will augment customer service agents' capabilities. Customer Experience (CX) will improve for the first time in three years. Improvements will be most pronounced in Europe and APAC. In North America, the US will improve, while Canada will continue to struggle. Marketers will become privacy champions . CMOs at five large consumer brands will fund dedicated privacy resources. Yet, only 17% of privacy decision-makers say that their organization's privacy team has marketing competencies or skills. To bust this bottleneck, five large B2C brands will earmark a portion of their marketing budget specifically to fund additional headcount to the privacy team and/or upskill existing privacy colleagues. Generative AI dominated the top 10 emerging technologies of 2023 report by Forrester. The research notes that generative AI will strain most firms' ability to take risks and make good bets on emerging technology. Forrester research on the impact of generative AI on marketing notes the benefits of scale and precision to marketing. The research identifies the following benefits: 1. enhancing human intuition with intelligence; 2. amplifying creators' work; and 3. adding scale and speed to creative quality. Top 10 Emerging Technologies 2023. Forrester Constellation Research believes generative AI will supercharge the future of work. The research notes that many work tasks will benefit from between a 1.3x to 5x gain in speed alone. Constellation research advice on the adoption of generative AI in the digital workplace is to have the following: Clear AI guidelines and policies Education and training AI governance structures Oversight and monitoring Collaboration and feedback Create clear ethical guidelines Conduct ethical impact assessments Monitor for AI bias Provide transparency Ensure compliance with regulations Constellation also provides a list of the leading generative AI enterprise grade solutions. Constellation also breaks down the impact of generative AI by industry . For the education industry, Constellation notes that Generative AI, which appears to be initially loved by students and loathed by educators, is coming to education as its embedded in courseware as well as learning-management systems. The overall forecasts are optimistic, but there are cautionary notes about guardrails for AI . Generative AI and the future of work. Constellation Research Ventana Research highlights how generative AI helps sales and marketing in practical ways. Ventana notes: \"For marketing, one way this will happen is by improving the efficiency of marketing copy and potentially enabling personalization at scale. For field sales, the suggestions are that generative AI will improve both the ability of sales to craft emails for outreach and responses and to enhance presentations. Other use cases include using generative AI to summarize calls automatically and post them to the associated opportunity record, improving both accuracy and timeliness. This will have positive effects on sales productivity, but on its own will represent less a revolution than an evolution.\" By 2025, more than one-quarter of sales organizations will utilize generative AI to auto-summarize meetings, personalize outreach at scale, and generate tailored sales enablement to improve sales productivity and allow more time for direct sales engagement to improve win rates, according to Ventana . The use of AI to advance automation and enhance efficiency is another example of intelligent automation as a powerful tool for CIOs. Also: ChatGPT is the most sought out tech skill in the workforce, says learning platform From Sept. 12-14, I attended the largest AI conference in the world, Salesforce Dreamforce . I met with technology analysts from all of the institutions listed above and more, to learn more about their latest points of view on the data revolution, generative AI market trends, and use-case forecasts for the next 12-18 months. I captured and followed up with updates here on the impact of generative AI on the future of work and enterprise. Featured Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "ZDNET looks back on tech in 2023, and looks ahead to 2024",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/zdnet-looks-back-on-tech-in-2023-and-looks-ahead-to-2024/",
  #     "publish_date": "20-12-2023",
  #     "content": "Getty/shunli zhao Generative AI may have dominated most of the headlines in tech during 2023, but there were plenty of other stories, trends, and products worth calling out. At least one of them -- Apple Vision Pro and the resurgence of AR and VR -- caused nearly AI-level buzz when it dropped in June. ZDNET's editors and writers are shining the spotlight on the most important developments in tech during 2023, and are happy to help you connect the dots on where things are headed in 2024. Of course, no one could hide the fact that ChatGPT -- and the generative AI that powers it -- was the biggest story of the year. There's an excellent chance that it could be the biggest story of the decade. Here are the articles where our team is looking back and looking ahead. And keep returning to this page throughout the end of 2023 and the beginning of 2024 as we add more links to the latest perspectives. Two breakthroughs made 2023 tech's most innovative year in over a decade - Jason Hiner These 5 major tech advances of 2023 were the biggest game-changers - Kerry Wan AI in 2023: A year of breakthroughs that left no human thing unchanged - Jason Perlow The promise and peril of AI at work in 2024, according to Deloitte's Tech Trends report - Sabrina Ortiz The future of work is more human than you'd think, say these business experts - Mark Samuels Generative AI filled us with wonder in 2023 - but all magic comes with a price - David Gewirtz 2023 was a big year for AI: The top countries using it and which AI tools they prefer - Maria Diaz AI at the edge: 5G and the Internet of Things see fast times ahead - Joe McKendrick Apple names the 14 best apps and games of 2023. Your next favorite app may be on the list - Sabrina Ortiz ZDNET editors' favorite tech products of 2023 - Allison Murray Featured reviews Apple Watch Series 9 review: Don't settle for the less expensive models this year. Here's why This adorable motion-tracking camera has proven to be indispensable in my smart home My favorite USB-C accessory of all time scored a magnetic upgrade OnePlus' first-ever foldable makes Samsung and Google's look outdated \u2013 and it's near perfect The Oura smart ring's brilliant new features outshine even its titanium finish Apple Watch Series 9 review: Don't settle for the less expensive models this year. Here's why This adorable motion-tracking camera has proven to be indispensable in my smart home My favorite USB-C accessory of all time scored a magnetic upgrade OnePlus' first-ever foldable makes Samsung and Google's look outdated \u2013 and it's near perfect The Oura smart ring's brilliant new features outshine even its titanium finish",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "The future of work is more human than you'd think, say these business experts",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/home-and-office/work-life/the-future-of-work-is-more-human-than-youd-think-say-these-business-experts/",
  #     "publish_date": "20-12-2023",
  #     "content": "AzmanL/Getty Images If you thought 2023 was a big year for the future of work , wait until you see what comes next. The impact of generative artificial intelligence (AI) will continue to dominate discussions about workplace roles in 2024. Add in pressures for hybrid-working strategies, sustainable operational practices, and the effect of other emerging technologies, and the future of work will be a key talking point for employers and employees next year. What's already clear is that work today, with its focus on decentralization and automation, is very different from the nature of labor even just a few years ago. Also: ZDNET looks back on tech in 2023, and looks ahead to 2024 Five-day office weeks have been replaced by a mix of working styles that stretch from the home to a video-conferencing platform. Increasing numbers of employees, meanwhile, are using generative AI tools , such as ChatGPT and Copilot , to work productively and effectively. This rapid move toward decentralization and automation would have seemed impossible at the start of the decade. However, the coronavirus pandemic and the exploitation of AI have set into motion a digital transformation that's brought the future of work into the present. What the experts say \"Work is a thing you do, not a place you go,\" says Ben Elms, chief revenue officer at internet connectivity specialist Expereo, to ZDNET in a one-to-one video chat. \"Post-COVID, we are now in a world where hybrid must exist. You've got to be able to manage distributed workforces around the globe, with some people in offices, some in homes, and everything in between.\" So, what happens next? With some solid technological foundations in place, what will be the direction of travel for the future of work through 2024 and beyond? Conversations with business and industry experts suggest the rate of change is only going to quicken, which brings challenges for both employees and employers. Also: Two breakthroughs made 2023 tech's most innovative year in over a decade David Brodeur-Johnson, principal analyst at Forrester, says this pace of change means business and digital leaders must focus on making sure professionals feel supported and engaged. Unfortunately, his firm's research suggests a full-blown employee experience (EX) recession could blow into enterprises through 2024, as employers take their collective eyes off the ball. Forrester suggests the business case for EX -- with a focus on diversity, equity, and inclusion, engagement, talent management, and the effective use of emerging technology -- is stronger than ever, but many leaders struggle to listen to their employees and put their concerns into action. Also: These 5 major tech advances of 2023 were the biggest game-changers The researcher says two key metrics have dropped between 2022 and 2023: employee engagement has fallen from 48% to 44% in the US, while culture energy has fallen from 69% to 66%. Even worse, Forrester expects engagement to fall to 39% next year, and culture energy to drop to 64%. People-first solutions are critical As a matter of urgency, Brodeur-Johnson says managers must listen to their staff and ensure the technologies they implement solve the workplaces challenges that employees face. \"A successful EX-focused strategy for 2024 and beyond is one that starts with a clear understanding of employees' jobs-to-be-done and works backwards into the technology stack to continuously improve their ability to be effective in their work every day,\" Brodeur-Johnson tells ZDNET. Also: The promise and peril of AI at work in 2024, according to Deloitte's Tech Trends report That singular focus on people-first innovation is a trend that resonates with Sandeep Raithatha, head of insights at technology firm Jabra. He tells ZDNET that any investment in technology should stem from a thorough understanding of present and future human requirements. His firm's recently released research on the future of work considers a range of global economic, cultural, and social trends. After reviewing hundreds of sources and interviewing 76 global experts, Jabra has identified six future-of-work scenarios that are highly likely to happen during the next five years. Here's a summary of those scenarios: Focus on employee wellbeing \u2013 Leveraging AI and using sensors to track and optimize employees and ensure they are healthy and happy. Agile superteams \u2013 Seamless cross-company collaboration and partnership between smaller full-time teams and a flexible network of partners. Sustainability at the heart of business \u2013 Exponential growth in communications technology as businesses reduce travel and create low-consumption supply chains. Office everywhere \u2013 Universal cloud technology and communications platforms will allow employees to work from wherever they want. Investing in the whole employee \u2013 Using data and AI to support a rapid growth in personal coaching that helps individuals stay motivated and focused. Consumerization of enterprise \u2013 Employees will select the devices and applications that best suit their work and personal lives in a hybrid style. Raithatha reflects on these six scenarios and says one of the key conclusions from the research is that the future of work is not mono-dimensional. \"Different forces and directions co-exist at the same time,\" he tells ZDNET. \"The ability to plan for and manage multiple scenarios is a key capability that business leaders need in the new year. A key enabler of this will be putting in place the culture and structures required to enable teams to succeed as circumstances evolve.\" Also: AI in 2023: A year of breakthroughs that left no human thing unchanged However, planning for the multi-dimensional future of work is far from straightforward, recognizes Expereo's Elms. \"The challenge is, 'How do you drive inclusivity? How do you make sure health and wellbeing is managed? How do you make sure you're watching out for those people who may not be engaging when you've got the complexity of multi-generational workforces, hybrid workforces, and distributed workforces around the world?'\" he asks. \"You really need leaders with a high degree of emotional intelligence, empathy, and the ability to sense how people are in order to drive the level of engagement that you need to help everybody feel fulfilled in doing what they do, and also achieve the organizational objectives.\" Making work meaningful Michelle Smith, program manager at Barnardo's, which is a British charity for vulnerable children, also says it's critical frontline staff spend as much time as possible engaging in fulfilling activities. She suggests to ZDNET in a video interview that happy workers are more likely to be productive -- and that's where the tactical use of technology can shape the future of work. Also: Generative AI filled us with wonder in 2023 - but all magic comes with a price Barnardo's, which supports over 370,000 children, young people, parents, and carers, is using Freshworks' IT service management platform Freshservice to ensure requests are dealt with quickly and effectively. \"Since the pandemic, there's been some huge shifts. We need to help reduce the additional pressures from work, which aren't part of the day job,\" says Smith. \"If we can relieve people from doing tedious manual work, then they can do more work on a person-to-person basis, which is much more enjoyable and impactful.\" The key message from industry and business leaders is the future of work is being molded by a complex range of factors that create significant challenges for us all. Also: ZDNET editors' favorite tech products of 2023 While some senior managers might be struggling to deal with a confluence of economic, cultural, and technological concerns, now is the time for employers to step up and create a human-first approach to work, says Jabra's Raithatha. \"By building this better future, business leaders can help reduce stress, enhance focus, improve performance, and positively benefit mental health in the workplace.\" Featured Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "How to use Bing Image Creator (and why it's better than ever)",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/how-to-use-bing-image-creator/",
  #     "publish_date": "20-12-2023",
  #     "content": "A photo generated with the Bing Image Creator using the prompt \"a photo of a robot taking a picture with a DSLR camera in a studio.\" Maria Diaz via Bing Image Creator/ZDNET As the use of different artificial intelligence (AI) tools has exploded in the past year, we've seen the development of generative AI sprouting in the most unlikely places. The release of OpenAI's ChatGPT last fall quickly led to Google, Microsoft, and Meta all coming up with new AI chatbots of their own with Bard , Bing Chat , and Meta AI . Along with that, Microsoft also released an AI image generator within Bing that is powered by DALL-E 3, the latest of OpenAI's projects. Microsoft was using a previous version of DALL-E to power its image creator until DALL-E 3 was incorporated into it, featuring improved image quality, more accurate prompt processing, and enhanced details within images. How to use: Midjourney | Craiyon AI | DALL-E 2 | Stable Diffusion | DALL-E 3 in ChatGPT Using the Bing Image Creator is possible through Bing Chat or directly on the tool's website, and is as easy as chatting with an AI chatbot like ChatGPT. How to use the new Bing Image Creator Would anyone believe this is a real Dodo Bird randomly found wandering about? Image created with Bing Image Creator. Maria Diaz via Bing Image Creator/ZDNET What you need : Using the Bing Image Creator only requires access to Bing.com, no need for an OpenAI account. The Bing Image Creator can be accessed via Bing Chat or by going to Bing.com/Create . We'll cover how to create images directly on the Bing Image Creator site , but you can find how to generate images in Bing Chat in the FAQ below. 1. Go to the Bing Image Creator and log in Unlike Bing Chat, you don't need Microsoft Edge to access the Bing Image Creator. Just go to Bing.com/Create and click on Join & Create to log in to your Microsoft account and access the image generator. On the homepage for the Bing Image Creator, click on Join & Create . Screenshot by Maria Diaz/ZDNET 2. Enter your prompt Next, enter a description of the image you want to prompt Bing to create for you. Just like when using an AI chatbot, be as descriptive as possible to ensure your result is accurate. After you enter your prompt in the text area, click on Create . Enter your prompt in the text area. Screenshot by Maria Diaz/ZDNET For this prompt, I'm going to request the following: \"photo of a dodo bird sitting on a concrete floor of a brightly lit home in the tropics.\" Then I'm going to click on Create and wait for my images to be generated. 3. View your results Once your images are ready, it's time to check the results. DALL-E and Bing's Image Creator will both typically display four generated images for each prompt. Also: How to use DALL-E 2 to turn your visions into AI-generated art They're not always great, as the free AI image generators are often not advanced enough to create truly lifelike images, so you may see some errors in details, such as a person's fingers or eye positioning, or the keys on a computer keyboard, for example. As you can see below, the images that were generated capture almost exactly what I prompted the Bing Image Creator to make. Asking Bing to create an image of a bird that is extinct was a big challenge as DALL-E 3 isn't trained on many different images of Dodo Birds because it went extinct in the 17th century. There are some resemblances to a pelican and a toucan in the images put out by Bing, but it is accurate enough, for the most part. The Bing Image Creator preview results created with the prompt I entered (highlighted at the top). Screenshot by Maria Diaz/ZDNET 4. Download your image(s) After looking through the generated images, I decided to download the picture below. Just clicking on an image will expand it and give you the options to Share , Save to your account, Download , or provide Feedback . It's worth noting that you can download one, all, or none of the images. This was my favorite photo of the four. Screenshot by Maria Diaz/ZDNET FAQs Can I create images using Microsoft Copilot or Bing Chat? There are two ways to use the Bing Image Creator. You can generate images by going to Bing.com/Create , as detailed above, or you can create images right from Microsoft Copilot or Bing Chat. I asked Bing Chat, \"create a photo of a lazy zebra in a room with navy walls and gold curtains.\" Screenshot by Maria Diaz/ZDNET Here's how you can ask the new Bing to create an image right from the chat window, the same process works for the Microsoft Copilot AI chatbot: Open Microsoft Edge Go to Bing.com Click on Chat Write your prompt, it can begin with a phrase like \"create an image\" or \"generate a photo\", but it's not necessary. Bing Chat typically recognizes your intent. Also: How to use the new Bing (and how it's different from ChatGPT) Bing Chat can create images in any conversation style, whether it's set to Creative, Balanced, or Precise. One of the pros of using Bing Chat to generate images is that you can ask follow-up questions to have Bing adjust the image, as the example above shows. Bing proposes questions like, \"Can you make the monkey wear a hat?\" and \"Change the color of the Vespa to blue\". How do you write prompts to create images using AI? The more specific you are in your prompts, the better; think of the prompt as a detailed description of the image you have in mind. Include adjectives, nouns, and verbs to describe the image and what the subject is doing -- even styles are encouraged. If you ask the AI bot to create \"a photo of...,\" you'll get a different result than if you say create a cartoon, a painting, or a 3D render; so the image style is important. This is the best way to build a successful Bing Image Creator prompt. Screenshot by Maria Diaz/ZDNET Here's how Bing's Image Creator recommends you format your prompts: Adjective + Noun + Verb + Style . Also: I've tested a lot of AI tools for work. These are my 5 favorite so far In the example above, that would be \"Fuzzy creature wearing sunglasses, digital art.\" You can use different terms to describe the style, as well, such as impressionism, cubism, abstract, etc. Do I own AI-generated images? The latest line from the United States Copyright Office (USCO) is that AI-generated images are not protected under current copyright laws because they are not the product of human authorship. Images generated with Bing have an invisible watermark to denote that it is AI-generated content. The watermark includes Bing's information and the date and time the image was generated. AI image generators have created controversy as they're AI bots trained on images found online, which have been created by someone else. While the art you create using an image creator tool is unique, it's created with the influences of millions of artists on the internet. Also: OpenAI unveils new safety plan for frontier AI models. How it'll impact future development The copyright ruling is subject to change. The USCO is holding listening sessions throughout 2023 to explore the subject more deeply and make necessary changes. Is Bing Image Creator free? Bing's Image Creator is free at this time, though you can pay for more boosts if you run out. Boosts are like credits, where each prompt you give it to create an image will cost you one of your boosts. Users used to get 25 boosts when they'd first start using the Image Creator, but it has since increased to 100. Once you run out of boosts, the Bing Image Creator will take longer to generate images after it's given a prompt. Instead of 10-30 seconds, it can take up to five minutes. Also: ChatGPT vs. Bing Chat: Which AI chatbot should you use? Microsoft was refilling boosts on a weekly basis, but has now switched to doing so daily. Users also have the option of redeeming Microsoft rewards in exchange for more boosts. Is Bing Image Creator the same as DALL-E 2? DALL-E 2 and the Bing Image Creator are not the same. As with GPT-4 in Bing Chat, Microsoft is incorporating the more advanced DALL-E 3 into its image creator. DALL-E 3 will be available for ChatGPT Plus subscribers in the coming weeks. Right now, Bing is the only way to use DALL-E 3 for free. Also: In search of the missing piece of generative AI: Unstructured data Is there a waitlist to use the Bing Image Creator? There is no waitlist to use the Bing Image Creator at this time. All you have to do is log in to the website with your Microsoft account, and you'll have access to it. Disclaimer: Using AI-generated images could lead to copyright violations, so people should be cautious if they're using the images for commercial purposes. More on AI tools How to use AI to compose email in BlueMail How to use Copilot (formerly called Bing Chat) How to use ChatGPT to write code How to use ChatGPT Plus: From web browsing to plugins How to use Bing Image Creator (and why it's better than ever) How to use ChatGPT How to use AI to compose email in BlueMail How to use Copilot (formerly called Bing Chat) How to use ChatGPT to write code How to use ChatGPT Plus: From web browsing to plugins How to use Bing Image Creator (and why it's better than ever) How to use ChatGPT",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "Security first in software? AI may help make this an everyday practice",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/security-first-in-software-ai-may-help-make-this-an-everyday-practice/",
  #     "publish_date": "19-12-2023",
  #     "content": "amgun/Getty Images DevSecOps -- like its fraternal twin, DevOps -- has been a process in play for several years now in software shops, intended to enable more collaborative and intelligent workflows. Now, AI is poised to add more juice to these efforts -- but many are still skeptical about its implications. Also: AI brings a lot more to the DevOps experience than meets the eye These are some of the takeaways from a recent survey out of the SANS Institute, involving 363 IT executives and managers, which finds rising interest in adding AI or machine learning capabilities to DevSecOps workflows. Just over the past year, there has been a significant increase (16%) in the use of AI or data science to improve DevSecOps through investigation and experimentation -- from 33% in 2022 to 49% in 2023. While interest in applying AI to the software development lifecycle is on the rise, there is also healthy skepticism about going full-throttle when injecting AI into workflows. \"A strong contingent of the respondents, approximately 30%, reported not using AI or data science capabilities at all,\" note the SANS authors, Ben Allen and Chris Edmundson. \"This may reflect issues such as the rising level of concern surrounding data privacy and ownership of intellectual property.\" DevSecOps, as defined in the report, \"represents the intersection of software development (Dev), security (Sec), and operations (Ops) with the objective of automating, monitoring, and integrating security throughout all phases of the software development lifecycle.\" In other words, establish processes to build in security right at the start -- the design phase -- and see it through to deployment. Ultimately, a well-functioning DevSecOps effort delivers \"reduced time to fix security issues, less burdensome security processes, and increased ownership of application security,\" Allen and Edmundson state. There has been an increase in pilot projects integrating security operations into both the \"AI and machine learning ops\" (19% fully or partially integrated) and \"data science operations\" (24%) categories. This is a \"possible indication that organizations are performing threat modeling and risk assessments prior to incorporating AI capabilities into products,\" the authors state. Also: Generative AI now requires developers to stretch cross-functionally. Here's why Many organizations feel an urgent need for more qualified DevSecOps personnel -- 38% report skills gaps in this area. \"Because demand continues to outweigh supply in this area, there is a real need to spark more interest in this ever-changing field,\" the authors urge. \"To cope with the scarcity of talent amid competitive pressures, organizations should further leverage proven DevSecOps practices and explore emerging technological capabilities.\" Platform engineering, intended to streamline the flow of software from idea to implementation, also is gaining ground -- fully or partially adopted by 27% of respondents. \"As the developer self-service features inherent in a platform engineering practice mature, it will be essential to leverage the orchestration used to build, package, test, and deploy an application to incorporate security testing and tooling at key points along the path that has been laid out,\" Allen and Edmundson state. \"A well-implemented software engineering platform, designed in close collaboration with security stakeholders, could likely meet an organization's application security orchestration and correlation objectives.\" Artificial Intelligence AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "OpenAI unveils new safety plan for frontier AI models. How it'll impact future development",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/openai-unveils-new-safety-plan-for-frontier-ai-models-how-itll-impact-future-development/",
  #     "publish_date": "19-12-2023",
  #     "content": "Dustin Chambers/Bloomberg via Getty Images OpenAI has had a big year, leading the generative AI race with ChatGPT . The success of it means that all eyes are on the company to set the appropriate precedent for future AI developments, and OpenAI has taken one step forward with a new safety plan. Also: With AI upgrade, Salesforce's Einstein Copilot will handle unstructured data This week, OpenAI published the initial beta version of its Preparedness Framework, a safety plan delineating the different precautions the company has put in place to ensure the safety of its frontier AI models. In the first element of the framework, the company commits to running consistent evaluations on its frontier models that push the models to their limits. OpenAI claims that these findings will help the company assess the risk of the models and measure the effectiveness of proposed mitigations. The evaluations' findings will then be shown in risk \"scorecards\" for OpenAI's frontier models, continually updated to reflect risk thresholds, including cybersecurity, persuasion, model autonomy, and CBRN (chemical, biological, radiological, and nuclear threats), as seen in the image below. OpenAI The risk thresholds will be classified into four risk safety levels: low, medium, high, and critical. That score will then determine how the company should proceed with the model. Models that earn a post-mitigation score of \"medium\" or below can be deployed, while only models with a post-mitigation score of \"high\" or below can be developed further, according to the post. Also: AI adds new fuel to autonomous enterprises, but don't write off humans OpenAI is also restructuring how the teams internally operate in making decisions. A dedicated Preparedness team will drive technical work to evaluate the frontier model's capabilities, such as running evaluations and synthesizing reports. Then, a cross-functional Safety Advisory Group will review all the reports and send them to Leadership and the Board of Directors. Lastly, leadership will remain in its position as the decision-maker; however, the Board of Directors will hold the right to reverse decisions. This addition is particularly noteworthy because it follows the turmoil that ensued early last month when Sam Altman was briefly ousted by the Board of Directors, only to be promptly reinstated as CEO with a new board. Other framework elements include developing a protocol for added safety and outside accountability, collaborating with external parties and internal teams to track real-world misuse, and pioneering new research in measuring how risk evolves as models scale, according to the release. Artificial Intelligence AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "In search of the missing piece of generative AI: Unstructured data",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/in-search-of-the-missing-piece-of-data-generative-ai-unstructured-data/",
  #     "publish_date": "19-12-2023",
  #     "content": "Getty Images/Westend61 In recent years, the spotlight has been on unstructured data -- text, graphics, documents, IoT streams -- all streams of data that hold tremendous, untapped value. The database industry underwent a continent-size shift to better accommodate and hopefully surface these assets. Also: What is generative AI and why is it so popular? Here's everything you need to know Often, a lack of awareness of truly hidden unstructured data sources or assets frustrated these efforts. While it is estimated that 90% of the information across enterprises is unstructured data, only 46% of organizations have made efforts to extract its value, according to an IDC survey . Now, technology and business leaders have another reason for pursuing and surfacing unstructured data: The rise of generative artificial intelligence . The companies and IT professionals that pushed themselves forward with unstructured data in recent years may find themselves in a better position to take advantage of generative AI -- and, conversely, employ AI to dig deeper into data stores. It's time for enterprises to step up \"management of unstructured data from sources such as IoT, as well as knowledge documents -- PowerPoints, text, Excel spreadsheets,\" says Matt Labovich , US data, analytics, and AI leader at PwC. \"They all contain valuable institutional knowledge about business operations and hold insights that can be harnessed using gen AI.\" While structured data strategies have traditionally received the majority of attention, it's time to turn attention to \"the significant role of unstructured data in the advancement of gen AI,\" Labovich urges. While previous AI initiatives had to focus on use cases where structured data was ready and abundant, \"the complexity of collecting, annotating, and synthesizing heterogeneous datasets made wider AI initiatives unviable,\" according to a recent global survey published in MIT Technology Review Insights, underwritten by Databricks. \"By contrast, generative AI's new ability to surface and utilize once-hidden data will power extraordinary new advances across the organization,\" writes the report's author, Adam Green . Also: AI is growing into its role as a development and testing assistant The ability to capture and pull value from such data is considered more critical than ever. Almost 70% of the survey's participating technology executives agree that data problems are the most likely factor to jeopardize their AI and machine learning goals. \"Text-generating AI systems, such as the popular ChatGPT, are built on large language models,\" Green says. \"LLMs train on a vast corpus of data to answer questions or perform tasks based on statistical likelihoods.\" AI applications \"rely on a solid data infrastructure that makes possible the collection, storage, and analysis of its vast data-verse,\" Green adds. \"Even before the business applications of generative AI became apparent in late 2022, a unified data platform for analytics and AI was viewed as crucial by nearly 70% of our survey respondents.\" More than two-thirds of survey respondents agree that unifying their data platforms for analytics and AI is crucial to their enterprise data strategies. The generative AI era requires a data infrastructure that is flexible, scalable, and efficient. The key is to \"democratize access to data and analytics, enhance security, and combine low-cost storage with high-performance querying.\" Pulling together unstructured data for today's AI is no overnight task. \"Mergers and acquisitions have resulted in fragmented IT architectures. Important documents, from research and development intelligence to design instructions for plants, have been lost to view, locked in offline proprietary file types,\" Green points out in the MIT report. Also: The promise and peril of AI at work in 2024, according to Deloitte's Tech Trends report \"Could we interrogate these documents using LLMs? Can we train models to give us insights we're not seeing in this vast world of documentation?\" According to Andrew Blyton , vice president and chief information officer of Incyte, and former VP of DuPont Water & Protection, \"We think that's an obvious use case. Language models promise to make such unstructured data much more valuable.\" Bringing data owners, analysts, and users into the process from across the business is also key to data success with gen AI. \"It's not solely the responsibility of the CIO,\" says Labovich. \"Business leaders must take charge, while the CIO enables and supports the process. Operational readiness and change management are key, which involves having executives across the business actively participating in the identification of critical data, embedding into workflows, and assuming the role of change champions to foster widespread adoption.\" Featured Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model Two breakthroughs made 2023 tech's most innovative year in over a decade AI in 2023: A year of breakthroughs that left no human thing unchanged These 5 major tech advances of 2023 were the biggest game-changers What is Gemini? Everything you should know about Google's new AI model",
  #     "scraped_date": "22-12-2023"
  #   },
  #   {
  #     "title": "This AI can find your location just by looking at a few photos",
  #     "topic": "Generative AI",
  #     "source": "zdnet",
  #     "source_url": "zdnet.com",
  #     "article_url": "https://zdnet.com/article/this-ai-can-find-your-location-just-by-looking-at-a-few-photos/",
  #     "publish_date": "19-12-2023",
  #     "content": "SOPA Images/Getty Images Safe social media practices include not posting photos that showcase personal information such as license plate numbers, street names, or house numbers. But what if I told you that generative AI could still find a way to locate you -- just from your photo's background? Also: The best AI chatbots: ChatGPT and other noteworthy alternatives As generative AI developments continue, new use cases are being identified. Now, graduate students at Stanford University have developed an application that can detect your location from a street view or even just an image. The project, called Predicting Image Geolocations (PIGEON), can -- in most cases -- accurately determine a specific location simply by looking at the Google Street View of the location. PIGEON can predict the country pictured with 92% accuracy, and it can pinpoint a location within 25 kilometers of the target location in over 40% of its guesses, according to the preprint paper . To understand how impressive that is, PIGEON ranked within the top 0.01% of GeoGuessr players, the game in which users guess the location of a photo taken from a Google Street View of the location. That game served as the genesis for this project. Stanford University PIGEON also beat one of the world's best professional GeoGuessr players, Trevor Rainbolt, in a series of six matches, streamed online with more than 1.7 million views. So how exactly does PIGEON work? The students leveraged CLIP, a neural network developed by OpenAI that can connect text and images by training it on the names of visual categories to be recognized. Then, inspired by GeoGuessr, PIGEON was trained on a dataset of 100,000 original, randomly sampled locations from GeoGuessr and a download set of four images to span an entire \"panorama\" in a given location, making a total of 400,000 images. Stanford University Compared to how many images other AI models are trained on, PIGEON's pales in comparison. For reference, OpenAI's popular image-generating model, DALL-E 2, is trained on hundreds of millions of images. The students also worked on a separate model called PIGEOTTO, which was trained on over four million photos derived from Flickr and Wikipedia to identify a location from a single image as input. PIGEOTTO's performance achieved impressive results on image geolocalization benchmarks, outperforming previous state-of-the-art results by up to 7.7% in city accuracy and 29.8% in country accuracy, according to the paper. Also: Apple Maps vs. Google Maps: iPhone users are switching back, but which is better? The paper addresses the ethical considerations associated with this model, including the benefits and risks. On one hand, image geolocalization has many positive use cases such as autonomous driving, visual investigations, and simply satisfying curiosity about where a photo was taken. However, the negative implications include the most blatant violation of privacy. As a result, the students have decided to not release the model weights publicly and have only released the code for academic validation, according to the paper. Artificial Intelligence AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives AI in 2023: A year of breakthroughs that left no human thing unchanged These are the jobs most likely to be taken over by AI AI at the edge: 5G and the Internet of Things see fast times ahead Almost half of tech executives say their organizations aren't ready for AI or other advanced initiatives",
  #     "scraped_date": "22-12-2023"
  #   },
  #   ]

  all_summarised_articles = ""

  for article in all_articles:
      
    # embedding_generated = False
    # #PERFORMING EMBEDDING ON ARTICLE CONTENT
    # try:
    #     print("Embedding article: ", article["title"])
    #     article_embedding = embedding_model.encode(article["content"])
    #     embedding_generated = True
        
    # except:
    #     print("Error with encoding article: ", article["title"])

    article_summarised = False
    article_embedded = False

    try:
      title = article["title"]
      content = article["content"]
      topic = article["topic"]
      source = article["source"]
      source_url = article["source_url"]
      article_url = article["article_url"]
      publish_date = article["publish_date"]
      scraped_date = article["scraped_date"]

      # OPENAI
      completion = openai_client.chat.completions.create(
          model="gpt-3.5-turbo-16k",
          messages=[
              {"role": "system", "content": "You are a helpful assistant. You are knowledgeable about the latest news in the fields of quantum computing and generative AI."},
              {"role": "user", "content": "Given the following article title: " + title + ", category: " + topic + ", and summarised content: " + content + ", please summarise the content in 30 words or less."}
          ]
      )

      # AZURE OPENAI
      # completion = openai_client.chat.completions.create(
      #     model="gpt-35-2",
      #     engine="gpt35_16",
      #     messages=[
      #         {"role": "system", "content": "You are a helpful assistant. You are knowledgeable about the latest news in the fields of quantum computing and generative AI."},
      #         {"role": "user", "content": "Given the following article title: " + title + ", category: " + topic + ", and summarised content: " + content + ", please summarise the content in 30 words or less."}
      #     ]
      # )

      summarised_content = completion.choices[0].message.content
      print(summarised_content)
      article_summarised = True
    except Exception as e:
      print(e)
      print("Error with summarising article: ", article["title"])

    if article_summarised:
      all_summarised_articles += summarised_content + "\n\n"
      article_embedding = embedding_model.encode(summarised_content)
      print(article_embedding)
      article_embedded = True
    else:
      print("Error with encoding and embedding article: ", article["title"])

    if article_summarised and article_embedded:
      print("Article summarised and embedded")
      # Check if the article already exists based on title or article_url
      existing_article = articles_collection.find_one({
          "$or": [
              {"title": title},
              {"article_url": article_url}
          ]
      })

      if existing_article:
          print("Article already exists")
      else:
          # If the article doesn't exist, insert the new article
          new_article = {
              "title": title,
              "topic": topic,
              "content": summarised_content,
              "source": source,
              "source_url": source_url,
              "article_url": article_url,
              "publish_date": publish_date,
              "scraped_date": scraped_date,
              "trends": [],
              "article_embedding": article_embedding.tolist()
          }
          try:
              articles_collection.insert_one(new_article)
              print("Article inserted successfully")
          except Exception as e:
              print("Error inserting article: ", str(e))

      time.sleep(16)

  # To OBTAIN A SUMMARY OF ALL ARTICLES OF THE CURRENT SOURCE
  # To OBTAIN MAIN TRENDS USING GPT
  completion = openai_client.chat.completions.create(
      model="gpt-3.5-turbo-16k",
      messages=[
          {"role": "system", "content": "You are a helpful assistant. You are knowledgeable about the latest news in the fields of quantum computing and generative AI."},
          {"role": "user", "content": "Given the following articles: \n\n" + all_summarised_articles + "\n\n, extract 5 trends that you observe from these articles, with each trend being 10 words or less. Additionally, for each trend, create a short write-up of about 75 words elaborating the trend. Have the trends be more general and less specific. An example of a general trend is as follows: 'Generative AI revolutionizes content creation with powerful neural networks.', and an example of a more specific trend is as follows: 'Google is making use of AI Generated Music'. List out the trends in the following format, where each trend and write up are in 1 sentence but delimeted by a semicolon (;) : \n\n 1. Short description and explanation of trend 1;Write-up for Trend 1.\n2. Short description and explanation of trend 2;Write-up for Trend 2.\n3. Short description and explanation of trend 3;Write-up for Trend 3 \n\n and so on"}
      ]
  )

  # AZURE OPENAI
  # completion = openai_client.chat.completions.create(
  #     model="gpt-35-2",
  #     engine="gpt35_16",
  #     messages=[
  #         {"role": "system", "content": "You are a helpful assistant. You are knowledgeable about the latest news in the fields of quantum computing and generative AI."},
  #         {"role": "user", "content": "Given the following articles: \n\n" + all_summarised_articles + "\n\n\n, summarise and extract out from the articles 1 to 5 trends that you observe, with each trend being 10 words or less. Additionally, create a short write-up of about 75 words elaborating the trend. Have the trends be more general and less specific. An example of a general trend is as follows: 'Generative AI revolutionizes content creation with powerful neural networks.', and an example of a more specific trend is as follows: 'Google is making use of AI Generated Music'. List out the trends in the following format: \n\n 1. Short description and explanation of trend 1;{Write-up for Trend 1}\n2. Short description and explanation of trend 2;{Write-up for Trend 2}\n3. Short description and explanation of trend 3;{Write-up for Trend 3} \n\n and so on"}
  #     ]
  # )

  trends = completion.choices[0].message.content

  print(trends)

  # SPLIT TRENDS INTO AN ARRAY OF TRENDS
  trends_list = trends.split("\n")
  print(trends_list)

  # REMOVE THE NUMBERS FROM THE TRENDS
  trends_arr = []
  for trend in trends_list:
      # FIND THE INDEX OF THE FIRST FULL STOP
      index = trend.find(".")
      # REMOVE THE NUMBER FROM THE TRENDS
      trend = trend[index+2:]

      print(trend)

      # FIND THE SEMICOLON TO SEPARATE THE TRENDS FROM THE WRITE-UPS
      semicolon_index = trend.find(";")
      trend_item = trend[:semicolon_index]
      write_up = trend[semicolon_index+1:]

      # print("----------------TREND----------------")
      # print(trend[:semicolon_index])
      # print("----------------WRITE-UP----------------")
      # print(trend[semicolon_index+1:])

      today = date.today()
      
      # MAKE A NEW OBJECT TO STORE THE TRENDS AND WRITE-UPS
      trend_obj = {
          "trend": trend_item,
          "write_up": write_up,
          "date_generated": today.strftime("%d-%m-%Y"),
          "articles": []
      }

      # APPEND THE TRENDS OBJECT TO THE TRENDS ARRAY
      trends_arr.append(trend_obj)

  # FILTER OUT OBJECTS WHERE EITHER THE TREND OR WRITE-UP IS EMPTY
  trends_arr = list(filter(lambda trend: trend["trend"] != "" and trend["write_up"] != "", trends_arr))

  # START ASSOCIATING TRENDS WITH ARTICLES
  
  # Create the Atlas Search index for the vector field (article_embedding)
  articles_collection.create_index(
    [("article_embedding", "text")],
    weights={"article_embedding": 1},
    default_language="english"
  )

  # Get the list of indexes for the collection
  indexes = articles_collection.list_indexes()
  # print("List of indexes for the collection:")
  # print(list(indexes))

  for trend in trends_arr:

    # GET THE TREND
    trend_name = trend["trend"]

    query_sentence = trend_name

    query_vector = (embedding_model.encode(query_sentence)).tolist()
    # Perform a vector search
    result = articles_collection.find(
        {
            "article_embedding": {
                "$vector": {
                    "$search": {"$vector": query_vector},
                    "$score": {"$meta": "searchScore"}
                }
            }
        }
    ).sort([("score", {"$meta": "searchScore"})])

    results = articles_collection.aggregate([
      {"$vectorSearch": {
        "queryVector": query_vector,
        "path": "article_embedding",
        "numCandidates": 100,
        "limit": 5,
        "index": "vector_index",
          }}
    ])

    for document in results:
      # GET THE OBJECT ID OF THE DOCUMENT
      document_id = document.get('_id')

      # GET THE DOCUMENT FROM THE COLLECTION
      curr_document = articles_collection.find_one({'_id': ObjectId(document_id)})

      # UPDATE TRENDS ARRAY IN THE DOCUMENT
      curr_document_trends = curr_document["trends"]

      # New Object to store trend + write up
      trend_obj = {
          "trend": trend_name,
          "write_up": trend["write_up"]
      }

      curr_document_trends.append(trend_obj)

      # UPDATE THE DOCUMENT IN THE COLLECTION
      articles_collection.update_one({'_id': ObjectId(document_id)}, {"$set": {"trends": curr_document_trends}})

      # CREATE SIMPLIFIED DOCUMENT OBJECT
      simplified_document = {
        "title": curr_document["title"],
        "topic": curr_document["topic"],
        "content": curr_document["content"],
        "source": curr_document["source"],
        "source_url": curr_document["source_url"],
        "article_url": curr_document["article_url"],
        "publish_date": curr_document["publish_date"],
        "scraped_date": curr_document["scraped_date"]
      }

      # APPEND THE DOCUMENT TO THE TRENDS OBJECT
      trend["articles"].append(simplified_document)

      
      

  # RETURN JSON RESPONSE
  return jsonify({
      "code": 200,
      "message": "Articles summarised and embedded successfully",
      "trends": trends_arr
  }), 200




    # print(trends_arr)

    # print(all_summarised_articles)

    # return trends_list
    # # IF COLLETION EXISTS - DELETE IT
    # if "articles_collection" in chroma_client.list_collections():
    #     chroma_client.delete_collection(name="articles_collection")

    # # CHROMA COLLECTION
    # chroma_article_collection = chroma_client.create_collection(name="articles_collection", embedding_function=sentence_transformer_ef)

    # all_articles_summarised = []
    

    # ITERATE THROUGH ALL ARTICLES IN ALL_ARTICLES
    # for articles in all_articles:
        
    #     # ITERATE THROUGH ALL ARTICLES IN EACH SOURCE
    #     for article in articles:

    #         # To SUMMARISE ARTICLE CONTENT USING GPT 
    #         title = article["title"]
    #         content = article["content"]
    #         topic = article["topic"]

    #         completion = openai_client.chat.completions.create(
    #             model="gpt-3.5-turbo-16k",
    #             messages=[
    #                 {"role": "system", "content": "You are a helpful assistant. You are knowledgeable about the latest news in the fields of quantum computing and generative AI."},
    #                 {"role": "user", "content": "Given the following article title: " + title + ", category: " + topic + ", and summarised content: " + content + ", please summarise the content in 30 words or less."}
    #             ]
    #         )

    #         summarised_content = completion.choices[0].message.content

    #         new_article = {
    #             "title": article["title"],
    #             "topic": article["topic"],
    #             "content": summarised_content,
    #             "source": article["source"],
    #             "source_url": article["source_url"],
    #             "article_url": article["article_url"],
    #             "publish_date": article["publish_date"],
    #             "scraped_date": article["scraped_date"],
    #             "trends": []
    #         }

    #         try:
    #             articles_collection.insert_one(new_article)
            
    #         except Exception as e:
    #             return jsonify({
    #                 "code": 500,
    #                 "message": "upload.py internal error: " + str(e)
    #             }), 500
    
    #     # CHROMADB IMPLEMENTATION - STORE ARTICLES IN CHROMADB
    #     chroma_articles = []
    #     metadatas = []
    #     ids = []

    #     # GET OUT MONGODB ARTICLES - STORE IN CHROMADB
    #     for article in articles_collection.find():
    #         chroma_articles.append(article["content"])
    #         metadata = {
    #             "source": article["source"],
    #             "topic": article["topic"],
    #             "source_url": article["source_url"],
    #             "article_url": article["article_url"],
    #             "publish_date": article["publish_date"],
    #             "scraped_date": article["scraped_date"],
    #         }
    #         metadatas.append(metadata)

    #         # GET ID FOR EACH ARTICLE - STORED AS OBJECTID IN MONGODB
    #         ids.append(str(article["_id"]))
    #         # print(article["_id"])    


    #     chroma_article_collection.add(
    #         documents=chroma_articles,
    #         metadatas=metadatas,
    #         ids=ids
    #     )

    #     # OBTAIN TRENDS FROM ARTICLES IN DB - USE GPT
    #     all_articles = ""

    #     # GET ALL ARTICLES FROM DB and APPEND TO article_summary
    #     count = 1
    #     for article in articles_collection.find():
    #         all_articles += str(count) + ". " + article["content"] + "\n"
    #         count += 1

    #     print(all_articles)
    #     print("----------------")

    #     # To OBTAIN A SUMMARY OF ALL ARTICLES OF THE CURRENT SOURCE
    #     completion = openai_client.chat.completions.create(
    #         model="gpt-3.5-turbo",
    #         messages=[
    #             {"role": "system", "content": "You are a helpful assistant. You are knowledgeable about the latest news in the fields of quantum computing and generative AI."},
    #             {"role": "user", "content": "Given the following articles: \n\n" + all_articles + "\n\n, summarise the articles into 1 comprehensive article which summarises all of the articles above. Keep the number of words to 500 words or less"}
    #         ]
    #     )

    #     summarised_articles = completion.choices[0].message.content

    #     all_articles_summarised.append(summarised_articles)

    # # ITERATE THROUGH ALL ARTICLES IN ALL_ARTICLES_SUMMARISED - APPEND TO ONE STRING
    # all_articles_summarised_string = ""
    # for article in all_articles_summarised:
    #     all_articles_summarised_string += article + "\n\n\n"


    # # To OBTAIN MAIN TRENDS USING GPT
    # completion = openai_client.chat.completions.create(
    #     model="gpt-3.5-turbo",
    #     messages=[
    #         {"role": "system", "content": "You are a helpful assistant. You are knowledgeable about the latest news in the fields of quantum computing and generative AI."},
    #         {"role": "user", "content": "Given the following articles: \n\n" + all_articles + "\n\n\n, summarise and extract out from the articles 10 general trends, with each being 10 words or less. Have the trends be more general and less specific. An example of a general trend is as follows: 'Generative AI revolutionizes content creation with powerful neural networks.', and an example of a more specific trend is as follows: 'Google is making use of AI Generated Music'. List out the trends in the following format: \n\n1. Trend 1\n2. Trend 2\n3. Trend 3\n4. Trend 4\n5. Trend 5"}
    #     ]
    # )

    # trends = completion.choices[0].message.content

    # # SPLIT TRENDS INTO AN ARRAY OF TRENDS
    # trends_list = trends.split("\n")

    # # REMOVE THE NUMBERS FROM THE TRENDS
    # trends_arr = []
    # for trend in trends_list:
    #     # FIND THE INDEX OF THE FIRST FULL STOP
    #     index = trend.find(".")
    #     # REMOVE THE NUMBER FROM THE TRENDS
    #     trends_arr.append(trend[index+2:])

    # # ITERATE THROUGH TREND IN TREND_ARR
    # for trend in trends_arr:

    #     # QUERY THE CHROMADB FOR THE TREND
    #     results = chroma_article_collection.query(
    #         query_texts=[f"Given the following trend: '{trend}'"],
    #         n_results=5,
    #         include=['documents']
    #     )
    
    #     ids_array = results['ids'][0]
    #     # ITERATE THROUGH IDS_ARRAY
    #     for article_id in ids_array:
            
    #         # RETRIEVE ARTICLE FROM MONGODB
    #         article = articles_collection.find_one({"_id": ObjectId(article_id)})

    #         # APPEND TREND TO ARTICLE
    #         article["trends"].append(trend)

    #         # UPDATE ARTICLE IN MONGODB
    #         articles_collection.update_one({"_id": ObjectId(article_id)}, {"$set": article})

        
    # return jsonify({
    #     "code": 201,
    #     "message": "Articles summarised and uploaded successfully. Trends generated successfully. Articles associated with trends successfully."
    # }), 201





# CURRENT PROBLEMS
# 1. NEED MORE ARTICLES - CURRENTLY ONLY HAVE 15 ARTICLES AND 10 TRENDS, THERE WILL BOUND TO BE OVERLAPS
# 2. DECIDING ON THE NUMBER OF ARTICLES TO ASSOCIATE WITH EACH TREND - CURRENTLY SET AT 2, WHAT IS THE IDEAL NUMBER?
# 3. WHAT IF AN ARTICLE IS ASSOCIATED WITH MORE THAN 1 TREND? HOW TO HANDLE THAT?


# NEXT STEPS
# 1. RECEIVING 30+ ARTICLES FROM 3 SOURCES, EACH SOURCE HAS 30 ARTICLES
# 2. NEED TO SUMMARISE THE ARTICLES FROM THE 3 SOURCES INTO 1 CONDENSED SUMMARY FOR ALL THE ARTICLES IN THAT SOURCE - USING GPT
# 3. STORE THE 3 SUMMARIES INTO AN ARRAY
# 4. ITERATE THROUGH THIS ARRAY, APPEND ALL 3 SUMMARIES INTO ONE STRING TO BE PASSED INTO GPT AS A PROMPT 
# 5. USE GPT TO GENERATE 10 TRENDS FROM THE 3 SUMMARIES



if __name__ == "__main__":
  app.run(port=5002, debug=True)
